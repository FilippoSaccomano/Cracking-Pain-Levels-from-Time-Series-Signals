# üéâ Implementazione Completata: Ensemble di 9 Modelli

## ‚úÖ Requisito Soddisfatto

Come richiesto, ho implementato un **ensemble di 9 modelli** invece di testare solo il modello migliore.

## üìÅ File Principale

**`pain_pirate_ensemble_complete.ipynb`**

Questo √® l'UNICO file da eseguire. Contiene tutto il codice necessario:
- Preprocessing dei dati
- Definizione architettura Conv1D + BiLSTM
- Training di 9 modelli
- Valutazione con EWA weighting
- Predizione su test set
- Generazione submission

## üéØ Implementazione

### Architettura: Conv1D + BiLSTM

```
Input (batch, timesteps, features)
  ‚Üì
Conv1D (kernel=3, padding=1) ‚Üí ReLU ‚Üí BatchNorm ‚Üí MaxPool(2) ‚Üí Dropout
  ‚Üì
Conv1D (kernel=3, padding=1) ‚Üí ReLU ‚Üí BatchNorm ‚Üí MaxPool(2) ‚Üí Dropout
  ‚Üì
Bidirectional LSTM ‚Üí BatchNorm
  ‚Üì
Dense(64) ‚Üí ReLU ‚Üí Dropout
  ‚Üì
Output (n_classes)
```

### 9 Modelli = 3 Configurazioni √ó 3 Seeds

**Config 1: 128x128x128** (3 seeds: 0, 1, 2)
- conv_dim: 128
- lstm_units: 128
- dropout: 0.117753
- lr: 0.000506
- label_smoothing: 0.034647
- max_epochs: 23

**Config 2: 128x128x160** (3 seeds: 100, 101, 102)
- conv_dim: 128
- lstm_units: 160
- dropout: 0.107198
- lr: 0.000302
- label_smoothing: 0.051445
- max_epochs: 37

**Config 3: 160x160x160** (3 seeds: 200, 201, 202)
- conv_dim: 160
- lstm_units: 160
- dropout: 0.114202
- lr: 0.000335
- label_smoothing: 0.051782
- max_epochs: 29

### EWA (Exponentially Weighted Average)

I modelli vengono pesati in base alla loro performance sul validation set:

```python
loss_i = 1 - F1_i
weight_i = exp(-eta * loss_i)
weights = weights / sum(weights)
```

Con `eta=15.0`, i modelli con F1 pi√π alto ricevono peso significativamente maggiore.

### Soft Voting Pesato

Le predizioni finali utilizzano soft voting:

```python
weighted_probs = sum(weight_i * probs_i for i in models)
final_prediction = argmax(softmax(weighted_probs))
```

## üöÄ Come Usare

### 1. Prerequisiti

Assicurati di avere:
- Python 3.12+
- PyTorch
- numpy, pandas, scikit-learn, scipy
- matplotlib, seaborn, tqdm

I file dati nella stessa directory del notebook:
- `pirate_pain_train.csv`
- `pirate_pain_train_labels.csv`
- `pirate_pain_test.csv`

### 2. Esecuzione

```bash
# Apri il notebook
jupyter notebook pain_pirate_ensemble_complete.ipynb

# Oppure con Jupyter Lab
jupyter lab pain_pirate_ensemble_complete.ipynb
```

Poi:
1. **Run All Cells** (Cell ‚Üí Run All)
2. Attendi il completamento (45-90 min su GPU, 3-6 ore su CPU)
3. Ottieni `submission_ensemble_9models.csv`

### 3. Output

Il notebook genera:
- **submission_ensemble_9models.csv**: File di submission per Kaggle
- **Grafici**: F1 scores dei modelli e pesi EWA
- **Metriche**: Classification report e confusion matrix su validation

## üìä Vantaggi dell'Ensemble

‚úÖ **Riduzione varianza**: La media di 9 modelli riduce l'overfitting
‚úÖ **Migliore generalizzazione**: Seeds diversi esplorano diversi minimi locali
‚úÖ **Voting pesato**: I modelli migliori hanno pi√π influenza nelle predizioni
‚úÖ **Robustezza**: L'ensemble √® meno sensibile a singoli modelli fallimentari

Tipicamente, l'ensemble ottiene **F1 score superiore di 1-3%** rispetto al best single model.

## üîß Device Support

Il notebook rileva automaticamente il device migliore disponibile:

1. **MPS** (Apple Silicon M1/M2/M3/M4)
2. **CUDA** (NVIDIA GPU)
3. **CPU** (fallback)

## ‚è±Ô∏è Tempi di Esecuzione Stimati

| Hardware | Tempo per modello | Tempo totale (9 modelli) |
|----------|------------------|--------------------------|
| CPU (Intel/AMD) | 20-40 min | 3-6 ore |
| GPU (CUDA) | 5-10 min | 45-90 min |
| MPS (M1/M2/M3/M4) | 5-10 min | 45-90 min |

## üìö Documentazione Aggiuntiva

- **README.md**: Panoramica del progetto con Quick Start
- **README_ENSEMBLE.md**: Guida dettagliata all'uso dell'ensemble
- **SUMMARY.md**: Questo file

## ‚úÖ Verifiche Effettuate

- [x] Sintassi Python corretta
- [x] Tutte le 3 configurazioni presenti
- [x] 3 seeds per configurazione (totale 9 modelli)
- [x] EWA weighting implementato (eta=15.0)
- [x] Soft voting pesato
- [x] Device auto-detection
- [x] Early stopping su validation F1
- [x] Preprocessing completo
- [x] Tutto in un unico notebook
- [x] Nessun file esterno .py necessario

## üéì Conclusione

L'implementazione √® **completa e pronta per l'uso**. Esegui semplicemente il notebook `pain_pirate_ensemble_complete.ipynb` e otterrai il file di submission migliorato con l'ensemble approach.

---

**Nota**: Come richiesto, TUTTO il codice √® contenuto nel notebook. Non ci sono file Python esterni da importare o dipendenze aggiuntive da installare oltre alle librerie standard.
