{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83c\udff4\u200d\u2620\ufe0f Ensemble con Optuna - Pipeline Completa\\n",
        "\\n",
        "Questo notebook integra **Optuna optimization** con **ensemble approach**:\\n",
        "1. Preprocessing e creazione finestre\\n",
        "2. **Optuna optimization** per trovare i migliori iperparametri\\n",
        "3. **Selezione automatica** dei migliori N modelli dai trial\\n",
        "4. **Training ensemble** con i modelli selezionati\\n",
        "5. **EWA weighting** basato su validation F1\\n",
        "6. **Predizione test** con ensemble\\n",
        "\\n",
        "## Vantaggi\\n",
        "- \ud83d\udd0d Optuna trova automaticamente i migliori iperparametri\\n",
        "- \ud83c\udfaf Ensemble usa i top N modelli invece di configurazioni manuali\\n",
        "- \u2696\ufe0f EWA pesa i modelli basandosi sulle performance\\n",
        "- \ud83d\ude80 Pipeline completamente automatizzata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "imports",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\filip\\anaconda3\\envs\\an2dl\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch: 2.9.0+cpu\n",
            "Device: cpu\n",
            "\u2705 Environment ready!\n"
          ]
        }
      ],
      "source": [
        "# Core libraries\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from torch.optim import Adam, AdamW\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# Stats and ML\n",
        "from statsmodels.tsa.stattools import acf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Set seeds\n",
        "SEED = 42\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette('husl')\n",
        "\n",
        "print(f'PyTorch: {torch.__version__}')\n",
        "print(f'Device: {device}')\n",
        "print('\u2705 Environment ready!')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "load_header",
      "metadata": {},
      "source": [
        "## 1. Caricamento Dati"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "load_data",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\ud83d\udcca Dataset Shape:\n",
            "  Features: (105760, 40)\n",
            "  Labels: (661, 2)\n",
            "  Samples: 661\n",
            "  Timesteps/sample: 160\n",
            "\n",
            "\ud83d\udccb Features: 4 pain_survey + 3 categorical + 31 joints\n",
            "\n",
            "\ud83c\udff7\ufe0f Labels (IMBALANCED - need class weighting):\n",
            "  no_pain: 511 (77.3%)\n",
            "  low_pain: 94 (14.2%)\n",
            "  high_pain: 56 (8.5%)\n"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "X_train = pd.read_csv('pirate_pain_train.csv')\n",
        "y_train = pd.read_csv('pirate_pain_train_labels.csv')\n",
        "\n",
        "print('\ud83d\udcca Dataset Shape:')\n",
        "print(f'  Features: {X_train.shape}')\n",
        "print(f'  Labels: {y_train.shape}')\n",
        "print(f'  Samples: {X_train[\"sample_index\"].nunique()}')\n",
        "print(f'  Timesteps/sample: {X_train.groupby(\"sample_index\").size().iloc[0]}')\n",
        "\n",
        "# Feature groups\n",
        "pain_survey_cols = [c for c in X_train.columns if 'pain_survey' in c]\n",
        "categorical_cols = ['n_legs', 'n_hands', 'n_eyes']\n",
        "joint_cols = [c for c in X_train.columns if 'joint_' in c]\n",
        "\n",
        "print(f'\\n\ud83d\udccb Features: {len(pain_survey_cols)} pain_survey + {len(categorical_cols)} categorical + {len(joint_cols)} joints')\n",
        "\n",
        "# ADVICE 08/11: Check class imbalance\n",
        "print(f'\\n\ud83c\udff7\ufe0f Labels (IMBALANCED - need class weighting):')\n",
        "for label, count in y_train['label'].value_counts().items():\n",
        "    print(f'  {label}: {count} ({100*count/len(y_train):.1f}%)')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "autocorr_header",
      "metadata": {},
      "source": [
        "## 2. ADVICE 11/11: Determinare WINDOW_SIZE\n",
        "\n",
        "*\"Its own echo, the series sings.\"*\n",
        "\n",
        "Usiamo autocorrelazione per scegliere window size basata sui dati."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "autocorr_code",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\ud83d\udd0d Analyzing autocorrelation...\n",
            "\u2705 WINDOW_SIZE from autocorrelation: 40\n",
            "   STRIDE: 20\n",
            "\ud83d\udca1 ADVICE 11/11: Data-driven window size!\n"
          ]
        }
      ],
      "source": [
        "# ADVICE 11/11: Analyze autocorrelation to determine optimal window\n",
        "print('\ud83d\udd0d Analyzing autocorrelation...')\n",
        "samples_analyze = X_train['sample_index'].unique()[:10]\n",
        "key_features = joint_cols[:6]\n",
        "\n",
        "optimal_lags = {}\n",
        "for feature in key_features:\n",
        "    sample_lags = []\n",
        "    for sid in samples_analyze:\n",
        "        data = X_train[X_train['sample_index']==sid][feature].values\n",
        "        if len(data) >= 50:\n",
        "            max_lags = min(len(data)//2-1, 80)\n",
        "            acf_vals = acf(data, nlags=max_lags)\n",
        "            sig_bound = 1.96/np.sqrt(len(data))\n",
        "            for lag in range(1, len(acf_vals)):\n",
        "                if abs(acf_vals[lag]) < sig_bound:\n",
        "                    sample_lags.append(lag)\n",
        "                    break\n",
        "            else:\n",
        "                sample_lags.append(max_lags)\n",
        "    if sample_lags:\n",
        "        optimal_lags[feature] = int(np.median(sample_lags))\n",
        "\n",
        "if optimal_lags:\n",
        "    suggested = int(np.median(list(optimal_lags.values())))\n",
        "    WINDOW_SIZE = max(min(suggested, 100), 40)\n",
        "else:\n",
        "    WINDOW_SIZE = 60\n",
        "\n",
        "WINDOW_STRIDE = WINDOW_SIZE // 2\n",
        "\n",
        "print(f'\u2705 WINDOW_SIZE from autocorrelation: {WINDOW_SIZE}')\n",
        "print(f'   STRIDE: {WINDOW_STRIDE}')\n",
        "print(f'\ud83d\udca1 ADVICE 11/11: Data-driven window size!')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "preproc_header",
      "metadata": {},
      "source": [
        "## 3. Preprocessing con ADVICE 07/11 e 12/11\n",
        "\n",
        "**ADVICE 07/11**: Map categorical per embeddings  \n",
        "**ADVICE 12/11**: Aggiungi time features ciclici"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "preproc_code",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 Preprocessing done:\n",
            "   - ADVICE 07/11: Categorical mapped\n",
            "   - ADVICE 12/11: Time features (sin, cos, norm) added\n",
            "   Shape: (105760, 43)\n"
          ]
        }
      ],
      "source": [
        "# ADVICE 07/11: Map categorical features\n",
        "cat_map = {\n",
        "    'n_legs': {'two': 0, 'one+peg_leg': 1},\n",
        "    'n_hands': {'two': 0, 'one+hook_hand': 1},\n",
        "    'n_eyes': {'two': 0, 'one+eye_patch': 1}\n",
        "}\n",
        "\n",
        "X_proc = X_train.copy()\n",
        "for col, mapping in cat_map.items():\n",
        "    X_proc[col] = X_proc[col].map(mapping).fillna(0).astype(int)\n",
        "\n",
        "# ADVICE 12/11: Add cyclical time features\n",
        "max_time = X_proc['time'].max()\n",
        "X_proc['time_sin'] = np.sin(2*np.pi*X_proc['time']/max_time)\n",
        "X_proc['time_cos'] = np.cos(2*np.pi*X_proc['time']/max_time)\n",
        "X_proc['time_norm'] = X_proc['time']/max_time\n",
        "\n",
        "print('\u2705 Preprocessing done:')\n",
        "print('   - ADVICE 07/11: Categorical mapped')\n",
        "print('   - ADVICE 12/11: Time features (sin, cos, norm) added')\n",
        "print(f'   Shape: {X_proc.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "windows_header",
      "metadata": {},
      "source": [
        "## 4. Creazione Finestre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "windows_code",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\ud83d\udd04 Creating windows...\n",
            "\u2705 Windows: (4627, 40, 41)\n",
            "   Labels: (4627,)\n"
          ]
        }
      ],
      "source": [
        "# Create sliding windows\n",
        "def create_windows(df, sample_idx, window_size, stride):\n",
        "    sample = df[df['sample_index']==sample_idx].sort_values('time')\n",
        "    feat_cols = [c for c in sample.columns if c not in ['sample_index','time']]\n",
        "    features = sample[feat_cols].values\n",
        "    \n",
        "    windows = []\n",
        "    for start in range(0, max(1, len(features)-window_size+1), stride):\n",
        "        end = min(start+window_size, len(features))\n",
        "        win = features[start:end]\n",
        "        if len(win) < window_size:\n",
        "            pad = np.zeros((window_size-len(win), win.shape[1]))\n",
        "            win = np.vstack([win, pad])\n",
        "        windows.append(win)\n",
        "    return windows\n",
        "\n",
        "print('\ud83d\udd04 Creating windows...')\n",
        "all_windows = []\n",
        "all_labels = []\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y_train['label'])\n",
        "\n",
        "for sid, label in zip(y_train['sample_index'], y_encoded):\n",
        "    wins = create_windows(X_proc, sid, WINDOW_SIZE, WINDOW_STRIDE)\n",
        "    all_windows.extend(wins)\n",
        "    all_labels.extend([label]*len(wins))\n",
        "\n",
        "X_windows = np.array(all_windows, dtype=np.float32)\n",
        "y_windows = np.array(all_labels, dtype=np.int64)\n",
        "\n",
        "print(f'\u2705 Windows: {X_windows.shape}')\n",
        "print(f'   Labels: {y_windows.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "split_code",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\ud83d\udcca Split: Train (3701, 40, 41), Val (926, 40, 41)\n",
            "\n",
            "\u2696\ufe0f ADVICE 08/11 - Class Weights:\n",
            "   high_pain: 3.929\n",
            "   low_pain: 2.345\n",
            "   no_pain: 0.431\n",
            "\n",
            "\u2705 DataLoaders ready (batch_size=16)\n"
          ]
        }
      ],
      "source": [
        "# Split and normalize\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "    X_windows, y_windows, test_size=0.2, random_state=SEED, stratify=y_windows\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_tr = scaler.fit_transform(X_tr.reshape(-1, X_tr.shape[-1])).reshape(X_tr.shape)\n",
        "X_val = scaler.transform(X_val.reshape(-1, X_val.shape[-1])).reshape(X_val.shape)\n",
        "\n",
        "print(f'\ud83d\udcca Split: Train {X_tr.shape}, Val {X_val.shape}')\n",
        "\n",
        "# ADVICE 08/11: Compute class weights\n",
        "class_weights_array = compute_class_weight('balanced', classes=np.unique(y_tr), y=y_tr)\n",
        "class_weights_tensor = torch.FloatTensor(class_weights_array).to(device)\n",
        "\n",
        "print(f'\\n\u2696\ufe0f ADVICE 08/11 - Class Weights:')\n",
        "for i, w in enumerate(class_weights_array):\n",
        "    print(f'   {label_encoder.classes_[i]}: {w:.3f}')\n",
        "\n",
        "# Create DataLoaders\n",
        "train_dataset = TensorDataset(\n",
        "    torch.FloatTensor(X_tr),\n",
        "    torch.LongTensor(y_tr)\n",
        ")\n",
        "val_dataset = TensorDataset(\n",
        "    torch.FloatTensor(X_val),\n",
        "    torch.LongTensor(y_val)\n",
        ")\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(f'\\n\u2705 DataLoaders ready (batch_size={BATCH_SIZE})')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "model_header",
      "metadata": {},
      "source": [
        "## 5. ADVICE 13/11: Conv1D + LSTM\n",
        "\n",
        "*\"A pattern in time, like a pattern in space it is.\"*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "model_code",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 ADVICE 13/11: Conv1D + LSTM created\n",
            "   Input: (40, 41)\n",
            "   Output: 3 classes\n",
            "   Parameters: 65,827\n"
          ]
        }
      ],
      "source": [
        "# ADVICE 13/11: Build Conv1D + LSTM model\n",
        "class ConvLSTMClassifier(nn.Module):\n",
        "    \"\"\"Hybrid CNN-LSTM for time series classification.\"\"\"\n",
        "    \n",
        "    def __init__(self, input_size, num_classes, \n",
        "                 conv_filters=[64, 64], lstm_units=128, dropout=0.5):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Conv1D layers for local pattern extraction\n",
        "        self.conv_layers = nn.ModuleList()\n",
        "        in_channels = input_size\n",
        "        \n",
        "        for filters in conv_filters:\n",
        "            self.conv_layers.append(nn.Sequential(\n",
        "                nn.Conv1d(in_channels, filters, kernel_size=3, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.BatchNorm1d(filters),\n",
        "                nn.MaxPool1d(2),\n",
        "                nn.Dropout(dropout)\n",
        "            ))\n",
        "            in_channels = filters\n",
        "        \n",
        "        # LSTM for temporal dependencies\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=conv_filters[-1],\n",
        "            hidden_size=lstm_units,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "        \n",
        "        # Classification head\n",
        "        self.fc1 = nn.Linear(lstm_units * 2, 64)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc2 = nn.Linear(64, num_classes)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # x: (batch, seq_len, features)\n",
        "        x = x.transpose(1, 2)  # -> (batch, features, seq_len) for Conv1D\n",
        "        \n",
        "        # Apply Conv1D layers\n",
        "        for conv in self.conv_layers:\n",
        "            x = conv(x)\n",
        "        \n",
        "        # Back to (batch, seq_len, features) for LSTM\n",
        "        x = x.transpose(1, 2)\n",
        "        \n",
        "        # LSTM\n",
        "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
        "        x = torch.cat([h_n[0], h_n[1]], dim=1)  # Concatenate bidirectional\n",
        "        \n",
        "        # Classification\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        return self.fc2(x)\n",
        "\n",
        "# Initialize model\n",
        "n_features = X_tr.shape[2]\n",
        "n_classes = len(label_encoder.classes_)\n",
        "\n",
        "model = ConvLSTMClassifier(\n",
        "    input_size=n_features,\n",
        "    num_classes=n_classes,\n",
        "    conv_filters=[32, 32],\n",
        "    lstm_units=64\n",
        ").to(device)\n",
        "\n",
        "print('\u2705 ADVICE 13/11: Conv1D + LSTM created')\n",
        "print(f'   Input: ({WINDOW_SIZE}, {n_features})')\n",
        "print(f'   Output: {n_classes} classes')\n",
        "print(f'   Parameters: {sum(p.numel() for p in model.parameters()):,}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "loss_header",
      "metadata": {},
      "source": [
        "## 6. ADVICE 09/11 + 08/11: Loss Function\n",
        "\n",
        "**ADVICE 09/11**: Label smoothing  \n",
        "**ADVICE 08/11**: Class weighting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "loss_code",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 Loss function initialized:\n",
            "   - ADVICE 09/11: Label smoothing (0.1)\n",
            "   - ADVICE 08/11: Class weights integrated\n"
          ]
        }
      ],
      "source": [
        "# ADVICE 09/11: Label Smoothing + ADVICE 08/11: Class Weighting\n",
        "class WeightedLabelSmoothingCE(nn.Module):\n",
        "    \"\"\"Combines label smoothing (ADVICE 09/11) and class weighting (ADVICE 08/11).\"\"\"\n",
        "    \n",
        "    def __init__(self, class_weights, smoothing=0.1):\n",
        "        super().__init__()\n",
        "        self.smoothing = smoothing\n",
        "        self.confidence = 1.0 - smoothing\n",
        "        self.register_buffer('class_weights', class_weights)\n",
        "    \n",
        "    def forward(self, pred, target):\n",
        "        pred = pred.log_softmax(dim=-1)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            true_dist = torch.zeros_like(pred)\n",
        "            true_dist.fill_(self.smoothing / (pred.size(-1) - 1))\n",
        "            true_dist.scatter_(1, target.unsqueeze(1), self.confidence)\n",
        "        \n",
        "        # Apply class weights\n",
        "        weights = self.class_weights[target]\n",
        "        return torch.mean(weights * torch.sum(-true_dist * pred, dim=-1))\n",
        "\n",
        "# Initialize loss function\n",
        "criterion = WeightedLabelSmoothingCE(\n",
        "    class_weights=class_weights_tensor,\n",
        "    smoothing=0.1\n",
        ")\n",
        "\n",
        "print('\u2705 Loss function initialized:')\n",
        "print('   - ADVICE 09/11: Label smoothing (0.1)')\n",
        "print('   - ADVICE 08/11: Class weights integrated')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "train_header",
      "metadata": {},
      "source": [
        "## 7. Training con ADVICE 10/11: Gradient Clipping\n",
        "\n",
        "*\"A step too great, from the precipice fall it makes you.\"*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "train_functions",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 Training functions defined with ADVICE 10/11 (gradient clipping)\n"
          ]
        }
      ],
      "source": [
        "# ADVICE 10/11: Training with gradient clipping\n",
        "def train_epoch(model, loader, criterion, optimizer, device, max_grad_norm=1.0):\n",
        "    \"\"\"Train one epoch with gradient clipping.\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    \n",
        "    for inputs, labels in loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        # ADVICE 10/11: Gradient clipping\n",
        "        if max_grad_norm is not None:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        all_preds.extend(outputs.argmax(1).cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "    \n",
        "    avg_loss = total_loss / len(loader)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "    return avg_loss, f1\n",
        "\n",
        "def eval_epoch(model, loader, criterion, device):\n",
        "    \"\"\"Evaluate one epoch.\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            all_preds.extend(outputs.argmax(1).cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    \n",
        "    avg_loss = total_loss / len(loader)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "    return avg_loss, f1, all_preds, all_labels\n",
        "\n",
        "print('\u2705 Training functions defined with ADVICE 10/11 (gradient clipping)')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e554f91b",
      "metadata": {},
      "source": [
        "### Configurazioni per la Grid Search\n",
        "\n",
        "Definisci qui le combinazioni di iperparametri da testare prima di eseguire il training finale.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e449d403",
      "metadata": {},
      "source": [
        "### Grid Search sugli iperparametri\n",
        "\n",
        "Eseguiamo un ciclo sulle configurazioni definite, valutando l'F1 macro su validation per selezionare la migliore."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "925e1c6c",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-14 00:24:15,735] A new study created in memory with name: conv_lstm_opt\n",
            "[I 2025-11-14 00:25:59,845] Trial 0 finished with value: 0.9750621817660924 and parameters: {'conv_filters': [128, 128], 'lstm_units': 160, 'dropout': 0.3188154855045433, 'lr': 0.0005257104915418183, 'weight_decay': 5.348466673482687e-05, 'label_smoothing': 0.05221552572589589, 'scheduler_factor': 0.5311983430756677, 'scheduler_patience': 2, 'early_stop_patience': 4, 'max_grad_norm': 1.8829834674647157, 'search_epochs': 34}. Best is trial 0 with value: 0.9750621817660924.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-14 00:28:26,576] Trial 1 finished with value: 0.977643662100553 and parameters: {'conv_filters': [160, 160], 'lstm_units': 192, 'dropout': 0.2879502720669003, 'lr': 0.0003513282523471821, 'weight_decay': 3.3827573301545166e-05, 'label_smoothing': 0.060489889516022716, 'scheduler_factor': 0.23067077583006365, 'scheduler_patience': 4, 'early_stop_patience': 7, 'max_grad_norm': 1.8296309975184604, 'search_epochs': 38}. Best is trial 1 with value: 0.977643662100553.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-14 00:29:19,961] Trial 2 finished with value: 0.9683570845690784 and parameters: {'conv_filters': [48, 96], 'lstm_units': 160, 'dropout': 0.25304796310425004, 'lr': 0.0004439580730743453, 'weight_decay': 1.8626376096072425e-06, 'label_smoothing': 0.12698416152502218, 'scheduler_factor': 0.3725835304005193, 'scheduler_patience': 4, 'early_stop_patience': 4, 'max_grad_norm': 1.1281720753296962, 'search_epochs': 15}. Best is trial 1 with value: 0.977643662100553.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-14 00:30:37,640] Trial 3 finished with value: 0.9748121525112244 and parameters: {'conv_filters': [160, 160], 'lstm_units': 160, 'dropout': 0.15283124140580828, 'lr': 0.00032075567174013936, 'weight_decay': 0.0005679855731283927, 'label_smoothing': 0.03595769370905515, 'scheduler_factor': 0.2750153842733519, 'scheduler_patience': 2, 'early_stop_patience': 6, 'max_grad_norm': 0.6647068225263149, 'search_epochs': 16}. Best is trial 1 with value: 0.977643662100553.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-14 00:31:47,428] Trial 4 finished with value: 0.9685542702229952 and parameters: {'conv_filters': [128, 128], 'lstm_units': 32, 'dropout': 0.36669511134607335, 'lr': 0.0004928276657608646, 'weight_decay': 0.00011516755857050543, 'label_smoothing': 0.03963365155691585, 'scheduler_factor': 0.29585880716810575, 'scheduler_patience': 5, 'early_stop_patience': 8, 'max_grad_norm': 1.857705442176708, 'search_epochs': 22}. Best is trial 1 with value: 0.977643662100553.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-14 00:31:56,308] Trial 5 pruned. \n",
            "[I 2025-11-14 00:31:59,823] Trial 6 pruned. \n",
            "[I 2025-11-14 00:32:09,474] Trial 7 pruned. \n",
            "[I 2025-11-14 00:32:12,613] Trial 8 pruned. \n",
            "[I 2025-11-14 00:32:16,815] Trial 9 pruned. \n",
            "[I 2025-11-14 00:32:47,628] Trial 10 pruned. \n",
            "[I 2025-11-14 00:32:58,110] Trial 11 pruned. \n",
            "[I 2025-11-14 00:33:00,817] Trial 12 pruned. \n",
            "[I 2025-11-14 00:33:04,500] Trial 13 pruned. \n",
            "[I 2025-11-14 00:33:21,644] Trial 14 pruned. \n",
            "[I 2025-11-14 00:33:25,841] Trial 15 pruned. \n",
            "[I 2025-11-14 00:33:33,200] Trial 16 pruned. \n",
            "[I 2025-11-14 00:33:36,854] Trial 17 pruned. \n",
            "[I 2025-11-14 00:33:39,611] Trial 18 pruned. \n",
            "[I 2025-11-14 00:33:45,896] Trial 19 pruned. \n",
            "[I 2025-11-14 00:34:00,943] Trial 20 pruned. \n",
            "[I 2025-11-14 00:35:21,798] Trial 21 finished with value: 0.9799949737834286 and parameters: {'conv_filters': [160, 160], 'lstm_units': 160, 'dropout': 0.1009876525994633, 'lr': 0.0003070928970945703, 'weight_decay': 0.0005963826391651269, 'label_smoothing': 0.03095790827224964, 'scheduler_factor': 0.2551160664165111, 'scheduler_patience': 2, 'early_stop_patience': 6, 'max_grad_norm': 0.806692384774235, 'search_epochs': 17}. Best is trial 21 with value: 0.9799949737834286.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-14 00:35:36,241] Trial 22 pruned. \n",
            "[I 2025-11-14 00:37:31,608] Trial 23 finished with value: 0.9840655741374453 and parameters: {'conv_filters': [128, 128], 'lstm_units': 160, 'dropout': 0.10719836946533634, 'lr': 0.00030160348105263263, 'weight_decay': 0.0008306955221071393, 'label_smoothing': 0.0514445601302129, 'scheduler_factor': 0.24164889313027996, 'scheduler_patience': 3, 'early_stop_patience': 6, 'max_grad_norm': 0.955732164499852, 'search_epochs': 37}. Best is trial 23 with value: 0.9840655741374453.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-14 00:37:41,701] Trial 24 pruned. \n",
            "[I 2025-11-14 00:38:29,862] Trial 25 pruned. \n",
            "[I 2025-11-14 00:40:17,947] Trial 26 finished with value: 0.9820912831158299 and parameters: {'conv_filters': [128, 128], 'lstm_units': 160, 'dropout': 0.10452605719751837, 'lr': 0.0003669110520955091, 'weight_decay': 0.0006590080484897349, 'label_smoothing': 0.03501941933057649, 'scheduler_factor': 0.3134768445690985, 'scheduler_patience': 3, 'early_stop_patience': 7, 'max_grad_norm': 0.7253641125155368, 'search_epochs': 25}. Best is trial 23 with value: 0.9840655741374453.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-14 00:40:31,149] Trial 27 pruned. \n",
            "[I 2025-11-14 00:40:40,270] Trial 28 pruned. \n",
            "[I 2025-11-14 00:40:49,007] Trial 29 pruned. \n",
            "[I 2025-11-14 00:40:57,998] Trial 30 pruned. \n",
            "[I 2025-11-14 00:42:47,094] Trial 31 finished with value: 0.9769902553185862 and parameters: {'conv_filters': [160, 160], 'lstm_units': 160, 'dropout': 0.11910357885479522, 'lr': 0.00034555236604470816, 'weight_decay': 0.0001293799618000982, 'label_smoothing': 0.0810353421471178, 'scheduler_factor': 0.23182722578161408, 'scheduler_patience': 4, 'early_stop_patience': 6, 'max_grad_norm': 0.5192842236392128, 'search_epochs': 33}. Best is trial 23 with value: 0.9840655741374453.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-14 00:42:50,820] Trial 32 pruned. \n",
            "[I 2025-11-14 00:42:55,121] Trial 33 pruned. \n",
            "[I 2025-11-14 00:42:58,739] Trial 34 pruned. \n",
            "[I 2025-11-14 00:43:01,349] Trial 35 pruned. \n",
            "[I 2025-11-14 00:43:04,655] Trial 36 pruned. \n",
            "[I 2025-11-14 00:43:13,260] Trial 37 pruned. \n",
            "[I 2025-11-14 00:43:22,179] Trial 38 pruned. \n",
            "[I 2025-11-14 00:43:25,225] Trial 39 pruned. \n",
            "[I 2025-11-14 00:43:33,916] Trial 40 pruned. \n",
            "[I 2025-11-14 00:43:43,956] Trial 41 pruned. \n",
            "[I 2025-11-14 00:43:53,539] Trial 42 pruned. \n",
            "[I 2025-11-14 00:44:31,898] Trial 43 pruned. \n",
            "[I 2025-11-14 00:44:45,006] Trial 44 pruned. \n",
            "[I 2025-11-14 00:44:48,362] Trial 45 pruned. \n",
            "[I 2025-11-14 00:44:50,865] Trial 46 pruned. \n",
            "[I 2025-11-14 00:45:06,929] Trial 47 pruned. \n",
            "[I 2025-11-14 00:45:11,744] Trial 48 pruned. \n",
            "[I 2025-11-14 00:45:19,643] Trial 49 pruned. \n",
            "[I 2025-11-14 00:45:22,146] Trial 50 pruned. \n",
            "[I 2025-11-14 00:45:30,809] Trial 51 pruned. \n",
            "[I 2025-11-14 00:45:39,538] Trial 52 pruned. \n",
            "[I 2025-11-14 00:45:43,768] Trial 53 pruned. \n",
            "[I 2025-11-14 00:45:48,636] Trial 54 pruned. \n",
            "[I 2025-11-14 00:46:03,140] Trial 55 pruned. \n",
            "[I 2025-11-14 00:46:07,223] Trial 56 pruned. \n",
            "[I 2025-11-14 00:46:14,796] Trial 57 pruned. \n",
            "[I 2025-11-14 00:46:25,904] Trial 58 pruned. \n",
            "[I 2025-11-14 00:46:39,692] Trial 59 pruned. \n",
            "[I 2025-11-14 00:46:43,046] Trial 60 pruned. \n",
            "[I 2025-11-14 00:46:53,940] Trial 61 pruned. \n",
            "[I 2025-11-14 00:46:59,202] Trial 62 pruned. \n",
            "[I 2025-11-14 00:47:14,109] Trial 63 pruned. \n",
            "[I 2025-11-14 00:47:16,982] Trial 64 pruned. \n",
            "[I 2025-11-14 00:47:26,347] Trial 65 pruned. \n",
            "[I 2025-11-14 00:47:36,048] Trial 66 pruned. \n",
            "[I 2025-11-14 00:47:39,912] Trial 67 pruned. \n",
            "[I 2025-11-14 00:47:43,812] Trial 68 pruned. \n",
            "[I 2025-11-14 00:47:48,197] Trial 69 pruned. \n",
            "[I 2025-11-14 00:47:50,662] Trial 70 pruned. \n",
            "[I 2025-11-14 00:47:53,684] Trial 71 pruned. \n",
            "[I 2025-11-14 00:47:56,767] Trial 72 pruned. \n",
            "[I 2025-11-14 00:47:59,961] Trial 73 pruned. \n",
            "[I 2025-11-14 00:48:09,592] Trial 74 pruned. \n",
            "[I 2025-11-14 00:48:20,124] Trial 75 pruned. \n",
            "[I 2025-11-14 00:48:24,216] Trial 76 pruned. \n",
            "[I 2025-11-14 00:48:28,382] Trial 77 pruned. \n",
            "[I 2025-11-14 00:48:32,250] Trial 78 pruned. \n",
            "[I 2025-11-14 00:48:34,519] Trial 79 pruned. \n",
            "[I 2025-11-14 00:48:47,353] Trial 80 pruned. \n",
            "[I 2025-11-14 00:48:51,037] Trial 81 pruned. \n",
            "[I 2025-11-14 00:48:54,716] Trial 82 pruned. \n",
            "[I 2025-11-14 00:48:58,490] Trial 83 pruned. \n",
            "[I 2025-11-14 00:49:02,241] Trial 84 pruned. \n",
            "[I 2025-11-14 00:49:18,166] Trial 85 pruned. \n",
            "[I 2025-11-14 00:49:24,651] Trial 86 pruned. \n",
            "[I 2025-11-14 00:49:29,171] Trial 87 pruned. \n",
            "[I 2025-11-14 00:49:36,749] Trial 88 pruned. \n",
            "[I 2025-11-14 00:50:01,036] Trial 89 pruned. \n",
            "[I 2025-11-14 00:50:10,746] Trial 90 pruned. \n",
            "[I 2025-11-14 00:50:13,787] Trial 91 pruned. \n",
            "[I 2025-11-14 00:50:22,631] Trial 92 pruned. \n",
            "[I 2025-11-14 00:50:25,593] Trial 93 pruned. \n",
            "[I 2025-11-14 00:50:28,320] Trial 94 pruned. \n",
            "[I 2025-11-14 00:50:32,018] Trial 95 pruned. \n",
            "[I 2025-11-14 00:50:36,676] Trial 96 pruned. \n",
            "[I 2025-11-14 00:50:39,866] Trial 97 pruned. \n",
            "[I 2025-11-14 00:50:43,144] Trial 98 pruned. \n",
            "[I 2025-11-14 00:50:46,898] Trial 99 pruned. \n",
            "[I 2025-11-14 00:50:50,608] Trial 100 pruned. \n",
            "[I 2025-11-14 00:51:06,578] Trial 101 pruned. \n",
            "[I 2025-11-14 00:51:11,874] Trial 102 pruned. \n",
            "[I 2025-11-14 00:51:22,612] Trial 103 pruned. \n",
            "[I 2025-11-14 00:51:32,226] Trial 104 pruned. \n",
            "[I 2025-11-14 00:51:42,739] Trial 105 pruned. \n",
            "[I 2025-11-14 00:51:50,490] Trial 106 pruned. \n",
            "[I 2025-11-14 00:51:54,825] Trial 107 pruned. \n",
            "[I 2025-11-14 00:51:58,490] Trial 108 pruned. \n",
            "[I 2025-11-14 00:52:05,130] Trial 109 pruned. \n",
            "[I 2025-11-14 00:52:14,837] Trial 110 pruned. \n",
            "[I 2025-11-14 00:52:24,755] Trial 111 pruned. \n",
            "[I 2025-11-14 00:52:39,377] Trial 112 pruned. \n",
            "[I 2025-11-14 00:52:54,141] Trial 113 pruned. \n",
            "[I 2025-11-14 00:53:08,599] Trial 114 pruned. \n",
            "[I 2025-11-14 00:53:13,398] Trial 115 pruned. \n",
            "[I 2025-11-14 00:53:16,684] Trial 116 pruned. \n",
            "[I 2025-11-14 00:53:20,359] Trial 117 pruned. \n",
            "[I 2025-11-14 00:53:23,467] Trial 118 pruned. \n",
            "[I 2025-11-14 00:53:27,187] Trial 119 pruned. \n",
            "[I 2025-11-14 00:53:35,211] Trial 120 pruned. \n",
            "[I 2025-11-14 00:53:40,031] Trial 121 pruned. \n",
            "[I 2025-11-14 00:55:58,537] Trial 122 finished with value: 0.9832166716373677 and parameters: {'conv_filters': [160, 160], 'lstm_units': 160, 'dropout': 0.11420156632770057, 'lr': 0.00033481623553354724, 'weight_decay': 2.9919174140020867e-05, 'label_smoothing': 0.051782143930710976, 'scheduler_factor': 0.34919001671647765, 'scheduler_patience': 4, 'early_stop_patience': 7, 'max_grad_norm': 1.1557043439717942, 'search_epochs': 29}. Best is trial 23 with value: 0.9840655741374453.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-14 00:56:08,209] Trial 123 pruned. \n",
            "[I 2025-11-14 00:56:17,738] Trial 124 pruned. \n",
            "[I 2025-11-14 00:56:30,790] Trial 125 pruned. \n",
            "[I 2025-11-14 00:56:34,657] Trial 126 pruned. \n",
            "[I 2025-11-14 00:56:39,519] Trial 127 pruned. \n",
            "[I 2025-11-14 00:56:43,237] Trial 128 pruned. \n",
            "[I 2025-11-14 00:56:49,256] Trial 129 pruned. \n",
            "[I 2025-11-14 00:56:56,386] Trial 130 pruned. \n",
            "[I 2025-11-14 00:57:13,056] Trial 131 pruned. \n",
            "[I 2025-11-14 00:57:27,795] Trial 132 pruned. \n",
            "[I 2025-11-14 00:57:37,372] Trial 133 pruned. \n",
            "[I 2025-11-14 00:57:46,859] Trial 134 pruned. \n",
            "[I 2025-11-14 00:57:49,652] Trial 135 pruned. \n",
            "[I 2025-11-14 00:57:54,357] Trial 136 pruned. \n",
            "[I 2025-11-14 00:58:03,024] Trial 137 pruned. \n",
            "[I 2025-11-14 00:58:06,809] Trial 138 pruned. \n",
            "[I 2025-11-14 00:58:11,612] Trial 139 pruned. \n",
            "[I 2025-11-14 00:58:25,849] Trial 140 pruned. \n",
            "[I 2025-11-14 00:58:33,019] Trial 141 pruned. \n",
            "[I 2025-11-14 00:58:43,457] Trial 142 pruned. \n",
            "[I 2025-11-14 00:58:52,096] Trial 143 pruned. \n",
            "[I 2025-11-14 00:58:55,550] Trial 144 pruned. \n",
            "[I 2025-11-14 00:59:19,370] Trial 145 pruned. \n",
            "[I 2025-11-14 00:59:27,510] Trial 146 pruned. \n",
            "[I 2025-11-14 00:59:43,854] Trial 147 pruned. \n",
            "[I 2025-11-14 00:59:55,754] Trial 148 pruned. \n",
            "[I 2025-11-14 01:00:11,749] Trial 149 pruned. \n",
            "[I 2025-11-14 01:00:15,069] Trial 150 pruned. \n",
            "[I 2025-11-14 01:00:17,788] Trial 151 pruned. \n",
            "[I 2025-11-14 01:00:33,579] Trial 152 pruned. \n",
            "[I 2025-11-14 01:00:37,929] Trial 153 pruned. \n",
            "[I 2025-11-14 01:00:45,997] Trial 154 pruned. \n",
            "[I 2025-11-14 01:00:55,435] Trial 155 pruned. \n",
            "[I 2025-11-14 01:01:04,127] Trial 156 pruned. \n",
            "[I 2025-11-14 01:01:09,080] Trial 157 pruned. \n",
            "[I 2025-11-14 01:01:21,603] Trial 158 pruned. \n",
            "[I 2025-11-14 01:01:31,228] Trial 159 pruned. \n",
            "[I 2025-11-14 01:01:33,530] Trial 160 pruned. \n",
            "[I 2025-11-14 01:01:45,839] Trial 161 pruned. \n",
            "[I 2025-11-14 01:01:54,299] Trial 162 pruned. \n",
            "[I 2025-11-14 01:02:06,476] Trial 163 pruned. \n",
            "[I 2025-11-14 01:02:09,880] Trial 164 pruned. \n",
            "[I 2025-11-14 01:02:18,287] Trial 165 pruned. \n",
            "[I 2025-11-14 01:02:22,752] Trial 166 pruned. \n",
            "[I 2025-11-14 01:02:31,574] Trial 167 pruned. \n",
            "[I 2025-11-14 01:02:35,261] Trial 168 pruned. \n",
            "[I 2025-11-14 01:03:17,410] Trial 169 pruned. \n",
            "[I 2025-11-14 01:03:33,243] Trial 170 pruned. \n",
            "[I 2025-11-14 01:03:49,158] Trial 171 pruned. \n",
            "[I 2025-11-14 01:04:05,160] Trial 172 pruned. \n",
            "[I 2025-11-14 01:04:10,431] Trial 173 pruned. \n",
            "[I 2025-11-14 01:04:48,401] Trial 174 pruned. \n",
            "[I 2025-11-14 01:05:26,631] Trial 175 pruned. \n",
            "[I 2025-11-14 01:05:36,193] Trial 176 pruned. \n",
            "[I 2025-11-14 01:05:50,366] Trial 177 pruned. \n",
            "[I 2025-11-14 01:05:59,821] Trial 178 pruned. \n",
            "[I 2025-11-14 01:06:09,342] Trial 179 pruned. \n",
            "[I 2025-11-14 01:06:12,649] Trial 180 pruned. \n",
            "[I 2025-11-14 01:06:22,273] Trial 181 pruned. \n",
            "[I 2025-11-14 01:06:36,502] Trial 182 pruned. \n",
            "[I 2025-11-14 01:07:06,603] Trial 183 pruned. \n",
            "[I 2025-11-14 01:07:17,219] Trial 184 pruned. \n",
            "[I 2025-11-14 01:07:27,014] Trial 185 pruned. \n",
            "[I 2025-11-14 01:07:56,303] Trial 186 pruned. \n",
            "[I 2025-11-14 01:08:04,046] Trial 187 pruned. \n",
            "[I 2025-11-14 01:08:13,658] Trial 188 pruned. \n",
            "[I 2025-11-14 01:08:18,472] Trial 189 pruned. \n",
            "[I 2025-11-14 01:08:23,873] Trial 190 pruned. \n",
            "[I 2025-11-14 01:08:33,554] Trial 191 pruned. \n",
            "[I 2025-11-14 01:08:38,354] Trial 192 pruned. \n",
            "[I 2025-11-14 01:08:43,119] Trial 193 pruned. \n",
            "[I 2025-11-14 01:08:46,642] Trial 194 pruned. \n",
            "[I 2025-11-14 01:08:56,081] Trial 195 pruned. \n",
            "[I 2025-11-14 01:08:59,784] Trial 196 pruned. \n",
            "[I 2025-11-14 01:09:03,895] Trial 197 pruned. \n",
            "[I 2025-11-14 01:09:13,385] Trial 198 pruned. \n",
            "[I 2025-11-14 01:09:20,794] Trial 199 pruned. \n",
            "[I 2025-11-14 01:09:26,113] Trial 200 pruned. \n",
            "[I 2025-11-14 01:09:35,853] Trial 201 pruned. \n",
            "[I 2025-11-14 01:09:42,759] Trial 202 pruned. \n",
            "[I 2025-11-14 01:09:46,283] Trial 203 pruned. \n",
            "[I 2025-11-14 01:09:50,084] Trial 204 pruned. \n",
            "[I 2025-11-14 01:09:53,437] Trial 205 pruned. \n",
            "[I 2025-11-14 01:09:58,737] Trial 206 pruned. \n",
            "[I 2025-11-14 01:10:08,313] Trial 207 pruned. \n",
            "[I 2025-11-14 01:10:21,259] Trial 208 pruned. \n",
            "[I 2025-11-14 01:10:24,804] Trial 209 pruned. \n",
            "[I 2025-11-14 01:10:27,580] Trial 210 pruned. \n",
            "[I 2025-11-14 01:10:43,592] Trial 211 pruned. \n",
            "[I 2025-11-14 01:10:47,628] Trial 212 pruned. \n",
            "[I 2025-11-14 01:10:51,934] Trial 213 pruned. \n",
            "[I 2025-11-14 01:10:56,562] Trial 214 pruned. \n",
            "[I 2025-11-14 01:11:06,289] Trial 215 pruned. \n",
            "[I 2025-11-14 01:11:11,045] Trial 216 pruned. \n",
            "[I 2025-11-14 01:11:20,499] Trial 217 pruned. \n",
            "[I 2025-11-14 01:11:23,847] Trial 218 pruned. \n",
            "[I 2025-11-14 01:11:32,697] Trial 219 pruned. \n",
            "[I 2025-11-14 01:11:36,259] Trial 220 pruned. \n",
            "[I 2025-11-14 01:11:47,989] Trial 221 pruned. \n",
            "[I 2025-11-14 01:11:51,939] Trial 222 pruned. \n",
            "[I 2025-11-14 01:13:23,746] Trial 223 finished with value: 0.984681236474159 and parameters: {'conv_filters': [128, 128], 'lstm_units': 128, 'dropout': 0.11775262021902702, 'lr': 0.0005057161812291795, 'weight_decay': 1.2290249626719205e-06, 'label_smoothing': 0.03464710093006009, 'scheduler_factor': 0.21208684021448007, 'scheduler_patience': 3, 'early_stop_patience': 6, 'max_grad_norm': 1.0677414965036354, 'search_epochs': 23}. Best is trial 223 with value: 0.984681236474159.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-14 01:13:27,930] Trial 224 pruned. \n",
            "[I 2025-11-14 01:14:00,299] Trial 225 pruned. \n",
            "[I 2025-11-14 01:14:09,209] Trial 226 pruned. \n",
            "[I 2025-11-14 01:14:13,543] Trial 227 pruned. \n",
            "[I 2025-11-14 01:14:22,129] Trial 228 pruned. \n",
            "[I 2025-11-14 01:14:29,730] Trial 229 pruned. \n",
            "[I 2025-11-14 01:14:39,281] Trial 230 pruned. \n",
            "[I 2025-11-14 01:14:43,404] Trial 231 pruned. \n",
            "[I 2025-11-14 01:14:47,424] Trial 232 pruned. \n",
            "[I 2025-11-14 01:14:59,171] Trial 233 pruned. \n",
            "[I 2025-11-14 01:15:07,459] Trial 234 pruned. \n",
            "[I 2025-11-14 01:15:10,731] Trial 235 pruned. \n",
            "[I 2025-11-14 01:15:27,822] Trial 236 pruned. \n",
            "[I 2025-11-14 01:15:32,861] Trial 237 pruned. \n",
            "[I 2025-11-14 01:15:38,135] Trial 238 pruned. \n",
            "[I 2025-11-14 01:15:41,875] Trial 239 pruned. \n",
            "[I 2025-11-14 01:15:44,582] Trial 240 pruned. \n",
            "[I 2025-11-14 01:15:52,373] Trial 241 pruned. \n",
            "[I 2025-11-14 01:16:08,228] Trial 242 pruned. \n",
            "[I 2025-11-14 01:16:12,333] Trial 243 pruned. \n",
            "[I 2025-11-14 01:16:16,442] Trial 244 pruned. \n",
            "[I 2025-11-14 01:16:24,523] Trial 245 pruned. \n",
            "[I 2025-11-14 01:16:39,712] Trial 246 pruned. \n",
            "[I 2025-11-14 01:16:48,830] Trial 247 pruned. \n",
            "[I 2025-11-14 01:16:59,205] Trial 248 pruned. \n",
            "[I 2025-11-14 01:17:15,032] Trial 249 pruned. \n",
            "[I 2025-11-14 01:17:18,361] Trial 250 pruned. \n",
            "[I 2025-11-14 01:17:32,279] Trial 251 pruned. \n",
            "[I 2025-11-14 01:17:35,222] Trial 252 pruned. \n",
            "[I 2025-11-14 01:17:43,733] Trial 253 pruned. \n",
            "[I 2025-11-14 01:17:52,269] Trial 254 pruned. \n",
            "[I 2025-11-14 01:17:56,514] Trial 255 pruned. \n",
            "[I 2025-11-14 01:18:01,663] Trial 256 pruned. \n",
            "[I 2025-11-14 01:18:06,029] Trial 257 pruned. \n",
            "[I 2025-11-14 01:18:10,452] Trial 258 pruned. \n",
            "[I 2025-11-14 01:18:13,470] Trial 259 pruned. \n",
            "[I 2025-11-14 01:18:21,106] Trial 260 pruned. \n",
            "[I 2025-11-14 01:18:24,054] Trial 261 pruned. \n",
            "[I 2025-11-14 01:18:27,126] Trial 262 pruned. \n",
            "[I 2025-11-14 01:18:35,155] Trial 263 pruned. \n",
            "[I 2025-11-14 01:18:39,002] Trial 264 pruned. \n",
            "[I 2025-11-14 01:18:48,380] Trial 265 pruned. \n",
            "[I 2025-11-14 01:18:53,736] Trial 266 pruned. \n",
            "[I 2025-11-14 01:19:06,444] Trial 267 pruned. \n",
            "[I 2025-11-14 01:19:10,316] Trial 268 pruned. \n",
            "[I 2025-11-14 01:19:18,174] Trial 269 pruned. \n",
            "[I 2025-11-14 01:19:22,019] Trial 270 pruned. \n",
            "[I 2025-11-14 01:19:28,892] Trial 271 pruned. \n",
            "[I 2025-11-14 01:19:37,395] Trial 272 pruned. \n",
            "[I 2025-11-14 01:19:39,844] Trial 273 pruned. \n",
            "[I 2025-11-14 01:19:43,259] Trial 274 pruned. \n",
            "[I 2025-11-14 01:19:51,165] Trial 275 pruned. \n",
            "[I 2025-11-14 01:19:55,058] Trial 276 pruned. \n",
            "[I 2025-11-14 01:20:08,058] Trial 277 pruned. \n",
            "[I 2025-11-14 01:20:16,707] Trial 278 pruned. \n",
            "[I 2025-11-14 01:20:21,696] Trial 279 pruned. \n",
            "[I 2025-11-14 01:20:24,377] Trial 280 pruned. \n",
            "[I 2025-11-14 01:20:32,956] Trial 281 pruned. \n",
            "[I 2025-11-14 01:20:40,614] Trial 282 pruned. \n",
            "[I 2025-11-14 01:20:43,712] Trial 283 pruned. \n",
            "[I 2025-11-14 01:20:47,128] Trial 284 pruned. \n",
            "[I 2025-11-14 01:20:50,670] Trial 285 pruned. \n",
            "[I 2025-11-14 01:21:00,049] Trial 286 pruned. \n",
            "[I 2025-11-14 01:21:04,296] Trial 287 pruned. \n",
            "[I 2025-11-14 01:21:08,168] Trial 288 pruned. \n",
            "[I 2025-11-14 01:21:12,066] Trial 289 pruned. \n",
            "[I 2025-11-14 01:21:15,018] Trial 290 pruned. \n",
            "[I 2025-11-14 01:21:18,792] Trial 291 pruned. \n",
            "[I 2025-11-14 01:21:26,012] Trial 292 pruned. \n",
            "[I 2025-11-14 01:21:29,207] Trial 293 pruned. \n",
            "[I 2025-11-14 01:21:44,934] Trial 294 pruned. \n",
            "[I 2025-11-14 01:21:50,990] Trial 295 pruned. \n",
            "[I 2025-11-14 01:22:05,451] Trial 296 pruned. \n",
            "[I 2025-11-14 01:22:14,179] Trial 297 pruned. \n",
            "[I 2025-11-14 01:22:24,373] Trial 298 pruned. \n",
            "[I 2025-11-14 01:22:31,466] Trial 299 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\ud83c\udfc1 Optuna terminato\n",
            "\ud83d\udd1d Best F1 val: 0.9847\n",
            "\ud83d\udd27 Best params:\n",
            "   conv_filters: [128, 128]\n",
            "   lstm_units: 128\n",
            "   dropout: 0.11775262021902702\n",
            "   lr: 0.0005057161812291795\n",
            "   weight_decay: 1.2290249626719205e-06\n",
            "   label_smoothing: 0.03464710093006009\n",
            "   scheduler_factor: 0.21208684021448007\n",
            "   scheduler_patience: 3\n",
            "   early_stop_patience: 6\n",
            "   max_grad_norm: 1.0677414965036354\n",
            "   search_epochs: 23\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "number",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "value",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "params_conv_filters",
                  "rawType": "object",
                  "type": "unknown"
                },
                {
                  "name": "params_dropout",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "params_early_stop_patience",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "params_label_smoothing",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "params_lr",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "params_lstm_units",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "params_max_grad_norm",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "params_scheduler_factor",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "params_scheduler_patience",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "params_search_epochs",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "params_weight_decay",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "state",
                  "rawType": "object",
                  "type": "string"
                }
              ],
              "ref": "9f030c91-e493-4e74-9b60-e663e0385b22",
              "rows": [
                [
                  "223",
                  "223",
                  "0.984681236474159",
                  "[128, 128]",
                  "0.11775262021902702",
                  "6",
                  "0.03464710093006009",
                  "0.0005057161812291795",
                  "128",
                  "1.0677414965036354",
                  "0.21208684021448007",
                  "3",
                  "23",
                  "1.2290249626719205e-06",
                  "COMPLETE"
                ],
                [
                  "23",
                  "23",
                  "0.9840655741374453",
                  "[128, 128]",
                  "0.10719836946533634",
                  "6",
                  "0.0514445601302129",
                  "0.00030160348105263263",
                  "160",
                  "0.955732164499852",
                  "0.24164889313027996",
                  "3",
                  "37",
                  "0.0008306955221071393",
                  "COMPLETE"
                ],
                [
                  "122",
                  "122",
                  "0.9832166716373677",
                  "[160, 160]",
                  "0.11420156632770057",
                  "7",
                  "0.051782143930710976",
                  "0.00033481623553354724",
                  "160",
                  "1.1557043439717942",
                  "0.34919001671647765",
                  "4",
                  "29",
                  "2.9919174140020867e-05",
                  "COMPLETE"
                ],
                [
                  "26",
                  "26",
                  "0.9820912831158299",
                  "[128, 128]",
                  "0.10452605719751837",
                  "7",
                  "0.03501941933057649",
                  "0.0003669110520955091",
                  "160",
                  "0.7253641125155368",
                  "0.3134768445690985",
                  "3",
                  "25",
                  "0.0006590080484897349",
                  "COMPLETE"
                ],
                [
                  "21",
                  "21",
                  "0.9799949737834286",
                  "[160, 160]",
                  "0.1009876525994633",
                  "6",
                  "0.03095790827224964",
                  "0.0003070928970945703",
                  "160",
                  "0.806692384774235",
                  "0.2551160664165111",
                  "2",
                  "17",
                  "0.0005963826391651269",
                  "COMPLETE"
                ],
                [
                  "1",
                  "1",
                  "0.977643662100553",
                  "[160, 160]",
                  "0.2879502720669003",
                  "7",
                  "0.060489889516022716",
                  "0.0003513282523471821",
                  "192",
                  "1.8296309975184604",
                  "0.23067077583006365",
                  "4",
                  "38",
                  "3.3827573301545166e-05",
                  "COMPLETE"
                ],
                [
                  "31",
                  "31",
                  "0.9769902553185862",
                  "[160, 160]",
                  "0.11910357885479522",
                  "6",
                  "0.0810353421471178",
                  "0.00034555236604470816",
                  "160",
                  "0.5192842236392128",
                  "0.23182722578161408",
                  "4",
                  "33",
                  "0.0001293799618000982",
                  "COMPLETE"
                ],
                [
                  "0",
                  "0",
                  "0.9750621817660924",
                  "[128, 128]",
                  "0.3188154855045433",
                  "4",
                  "0.05221552572589589",
                  "0.0005257104915418183",
                  "160",
                  "1.8829834674647157",
                  "0.5311983430756677",
                  "2",
                  "34",
                  "5.348466673482687e-05",
                  "COMPLETE"
                ],
                [
                  "3",
                  "3",
                  "0.9748121525112244",
                  "[160, 160]",
                  "0.15283124140580828",
                  "6",
                  "0.03595769370905515",
                  "0.00032075567174013936",
                  "160",
                  "0.6647068225263149",
                  "0.2750153842733519",
                  "2",
                  "16",
                  "0.0005679855731283927",
                  "COMPLETE"
                ],
                [
                  "4",
                  "4",
                  "0.9685542702229952",
                  "[128, 128]",
                  "0.36669511134607335",
                  "8",
                  "0.03963365155691585",
                  "0.0004928276657608646",
                  "32",
                  "1.857705442176708",
                  "0.29585880716810575",
                  "5",
                  "22",
                  "0.00011516755857050543",
                  "COMPLETE"
                ],
                [
                  "2",
                  "2",
                  "0.9683570845690784",
                  "[48, 96]",
                  "0.25304796310425004",
                  "4",
                  "0.12698416152502218",
                  "0.0004439580730743453",
                  "160",
                  "1.1281720753296962",
                  "0.3725835304005193",
                  "4",
                  "15",
                  "1.8626376096072425e-06",
                  "COMPLETE"
                ],
                [
                  "169",
                  "169",
                  "0.9384300517412103",
                  "[160, 160]",
                  "0.14067273812185535",
                  "6",
                  "0.04735944874920424",
                  "0.00033630001374393176",
                  "192",
                  "0.7813561451563166",
                  "0.5503519606288055",
                  "3",
                  "29",
                  "1.9133390632512087e-05",
                  "PRUNED"
                ],
                [
                  "25",
                  "25",
                  "0.9380756297778973",
                  "[160, 160]",
                  "0.16398834362088238",
                  "6",
                  "0.015814248960588348",
                  "0.0003023215087770401",
                  "192",
                  "0.9345074728097488",
                  "0.27994228123893083",
                  "4",
                  "30",
                  "0.0004715124838998999",
                  "PRUNED"
                ],
                [
                  "43",
                  "43",
                  "0.9340905498865953",
                  "[160, 160]",
                  "0.13801266940332613",
                  "6",
                  "0.08143901725537346",
                  "0.0003474815909729817",
                  "160",
                  "0.5917229517060212",
                  "0.2822793466573937",
                  "4",
                  "39",
                  "1.9786638028179094e-05",
                  "PRUNED"
                ],
                [
                  "175",
                  "175",
                  "0.932068385994231",
                  "[160, 160]",
                  "0.1211436359212277",
                  "7",
                  "0.0499506112902239",
                  "0.0003134772947945622",
                  "160",
                  "0.6731397522149042",
                  "0.5473396948763607",
                  "3",
                  "28",
                  "2.8469026795936016e-05",
                  "PRUNED"
                ],
                [
                  "186",
                  "186",
                  "0.9294825117618745",
                  "[160, 160]",
                  "0.12563425813408782",
                  "7",
                  "0.05337105652976262",
                  "0.0003229058255095804",
                  "160",
                  "0.6529010014212986",
                  "0.5422408275622729",
                  "5",
                  "17",
                  "7.297679397082751e-05",
                  "PRUNED"
                ],
                [
                  "145",
                  "145",
                  "0.9272751385822757",
                  "[128, 128]",
                  "0.14340108001173363",
                  "7",
                  "0.033248463127386385",
                  "0.0005352182987351939",
                  "128",
                  "0.9083244481904765",
                  "0.22919946925183304",
                  "3",
                  "27",
                  "9.927492737091389e-06",
                  "PRUNED"
                ],
                [
                  "10",
                  "10",
                  "0.9266048503711578",
                  "[128, 64]",
                  "0.12628287152307519",
                  "5",
                  "0.07993276199267725",
                  "0.000397100746777746",
                  "64",
                  "0.8716399440039226",
                  "0.20701502992714",
                  "3",
                  "27",
                  "0.0009569541437776744",
                  "PRUNED"
                ],
                [
                  "174",
                  "174",
                  "0.924444791626933",
                  "[160, 160]",
                  "0.12117482256243899",
                  "7",
                  "0.04975152778286758",
                  "0.0005375591403738264",
                  "160",
                  "0.8420359129504298",
                  "0.5534532314512435",
                  "3",
                  "28",
                  "1.823699978235703e-05",
                  "PRUNED"
                ],
                [
                  "225",
                  "225",
                  "0.9237988368037978",
                  "[128, 128]",
                  "0.1309720031436479",
                  "6",
                  "0.034384451884856136",
                  "0.0005011963814660466",
                  "128",
                  "1.0828915040903273",
                  "0.2057489568379789",
                  "3",
                  "23",
                  "1.7790080450261192e-06",
                  "PRUNED"
                ],
                [
                  "183",
                  "183",
                  "0.905747698696016",
                  "[160, 160]",
                  "0.11296142784632392",
                  "7",
                  "0.044946797276159196",
                  "0.00035465630495876295",
                  "160",
                  "0.5758843707534171",
                  "0.5402461137470693",
                  "2",
                  "16",
                  "8.232331541096653e-05",
                  "PRUNED"
                ],
                [
                  "89",
                  "89",
                  "0.9018199751070588",
                  "[160, 160]",
                  "0.13061854559869812",
                  "7",
                  "0.05080087431894472",
                  "0.0003335038324486475",
                  "160",
                  "1.1864240284013832",
                  "0.40232830665863134",
                  "4",
                  "42",
                  "1.5154247257722866e-05",
                  "PRUNED"
                ],
                [
                  "242",
                  "242",
                  "0.8984269781689093",
                  "[128, 128]",
                  "0.10910004437948717",
                  "6",
                  "0.03952604390130763",
                  "0.0005249424250241113",
                  "128",
                  "0.8809281434063182",
                  "0.21974028935516607",
                  "3",
                  "25",
                  "1.0073445578665035e-06",
                  "PRUNED"
                ],
                [
                  "147",
                  "147",
                  "0.8965740558212597",
                  "[128, 128]",
                  "0.14311304147016068",
                  "6",
                  "0.07347512340879395",
                  "0.0005468990091521772",
                  "128",
                  "0.8210700997009664",
                  "0.237944361111254",
                  "3",
                  "27",
                  "1.743803309784552e-05",
                  "PRUNED"
                ],
                [
                  "14",
                  "14",
                  "0.8904000646849209",
                  "[160, 160]",
                  "0.18082994586182954",
                  "7",
                  "0.022335297888889542",
                  "0.0006212461771106012",
                  "32",
                  "1.5751712468288874",
                  "0.5928435614418335",
                  "2",
                  "27",
                  "9.890176174675636e-06",
                  "PRUNED"
                ],
                [
                  "296",
                  "296",
                  "0.8859811133125337",
                  "[160, 160]",
                  "0.12583931325269504",
                  "7",
                  "0.03667452011308329",
                  "0.0003144969748070509",
                  "160",
                  "0.8462626251833834",
                  "0.4025214916761301",
                  "2",
                  "48",
                  "7.858002732012236e-06",
                  "PRUNED"
                ],
                [
                  "161",
                  "161",
                  "0.8858566988935394",
                  "[128, 128]",
                  "0.14600273689752144",
                  "6",
                  "0.10498667246777107",
                  "0.0005596801209682753",
                  "128",
                  "0.8095150168550443",
                  "0.24116070282252045",
                  "3",
                  "28",
                  "2.116336199306835e-05",
                  "PRUNED"
                ],
                [
                  "251",
                  "251",
                  "0.8848509717978562",
                  "[160, 160]",
                  "0.1349108971475932",
                  "6",
                  "0.013622442442867179",
                  "0.0003016894249978112",
                  "160",
                  "1.0616668168112302",
                  "0.24329837095268805",
                  "3",
                  "27",
                  "9.620421387415583e-06",
                  "PRUNED"
                ],
                [
                  "267",
                  "267",
                  "0.8845119475830189",
                  "[160, 160]",
                  "0.2268725109264823",
                  "8",
                  "0.0326710133701724",
                  "0.0003666936538705896",
                  "160",
                  "0.6462479934838277",
                  "0.5912476250732692",
                  "5",
                  "15",
                  "2.5172979371156285e-05",
                  "PRUNED"
                ],
                [
                  "163",
                  "163",
                  "0.8837453558105833",
                  "[128, 128]",
                  "0.1371308932371694",
                  "6",
                  "0.07268291691177764",
                  "0.000522522886147553",
                  "128",
                  "0.9148569803420009",
                  "0.21840052214224218",
                  "3",
                  "38",
                  "1.3329095196906502e-05",
                  "PRUNED"
                ],
                [
                  "182",
                  "182",
                  "0.883663641863279",
                  "[160, 160]",
                  "0.1336831165249693",
                  "7",
                  "0.0370203089121647",
                  "0.0003325170278803575",
                  "160",
                  "0.9065502107497221",
                  "0.5326283901664224",
                  "4",
                  "15",
                  "3.179330580750388e-05",
                  "PRUNED"
                ],
                [
                  "149",
                  "149",
                  "0.8836074740659119",
                  "[128, 128]",
                  "0.11119120707945561",
                  "6",
                  "0.03677789954864281",
                  "0.0005311738259963127",
                  "128",
                  "0.915166202252752",
                  "0.2240570197681081",
                  "3",
                  "24",
                  "1.3984661985303896e-06",
                  "PRUNED"
                ],
                [
                  "211",
                  "211",
                  "0.8824997612924915",
                  "[128, 128]",
                  "0.14374922572072166",
                  "6",
                  "0.0807888480528653",
                  "0.0005311702993868057",
                  "128",
                  "0.8411382381214484",
                  "0.23607861457391777",
                  "3",
                  "27",
                  "1.7979022540877034e-05",
                  "PRUNED"
                ],
                [
                  "92",
                  "92",
                  "0.8824907527698712",
                  "[128, 64]",
                  "0.11929529398098451",
                  "4",
                  "0.05863620137609713",
                  "0.00042842877401188986",
                  "64",
                  "0.8923498559566085",
                  "0.2236412754970817",
                  "3",
                  "30",
                  "0.000702150951924504",
                  "PRUNED"
                ],
                [
                  "170",
                  "170",
                  "0.8824457413931098",
                  "[160, 160]",
                  "0.10053461722729659",
                  "7",
                  "0.04766779704416084",
                  "0.0003775018610850554",
                  "192",
                  "1.9257108107187286",
                  "0.5246037074424084",
                  "4",
                  "29",
                  "0.00047117433919238364",
                  "PRUNED"
                ],
                [
                  "277",
                  "277",
                  "0.8819246345540067",
                  "[160, 160]",
                  "0.13273852292283944",
                  "7",
                  "0.008409889625611731",
                  "0.0003110290608023732",
                  "160",
                  "1.6766853000026671",
                  "0.5446228854916739",
                  "3",
                  "18",
                  "0.0005977041124577981",
                  "PRUNED"
                ],
                [
                  "132",
                  "132",
                  "0.8815219449761434",
                  "[160, 160]",
                  "0.13890532023979707",
                  "7",
                  "0.06159918420791318",
                  "0.00032505310431298485",
                  "160",
                  "1.1664083761812987",
                  "0.3747123127386653",
                  "4",
                  "42",
                  "2.5581691288919487e-05",
                  "PRUNED"
                ],
                [
                  "221",
                  "221",
                  "0.8810497284175036",
                  "[128, 128]",
                  "0.10540746774617392",
                  "6",
                  "0.036757512631901065",
                  "0.0005459070104469037",
                  "128",
                  "0.9195963538993496",
                  "0.22092945332729907",
                  "3",
                  "22",
                  "1.3870957715956262e-06",
                  "PRUNED"
                ],
                [
                  "236",
                  "236",
                  "0.8801222407075201",
                  "[128, 128]",
                  "0.12357296622576344",
                  "6",
                  "0.03511160485460092",
                  "0.0004292079418862914",
                  "160",
                  "1.1020451320535767",
                  "0.2229358085719666",
                  "4",
                  "36",
                  "0.0006758802652365841",
                  "PRUNED"
                ],
                [
                  "85",
                  "85",
                  "0.8783915434949314",
                  "[160, 160]",
                  "0.21676066147437187",
                  "7",
                  "0.112856654858639",
                  "0.000532537798076434",
                  "192",
                  "0.969947773285266",
                  "0.2897389933987254",
                  "4",
                  "28",
                  "7.672340218670033e-05",
                  "PRUNED"
                ],
                [
                  "172",
                  "172",
                  "0.8783520312701253",
                  "[160, 160]",
                  "0.14221409920266026",
                  "5",
                  "0.05281681186952127",
                  "0.00034700723713628986",
                  "192",
                  "0.7881711569252648",
                  "0.2897479494955481",
                  "3",
                  "30",
                  "2.307717806240377e-05",
                  "PRUNED"
                ],
                [
                  "171",
                  "171",
                  "0.8779237445275297",
                  "[160, 160]",
                  "0.15283865050770012",
                  "6",
                  "0.04038297025770919",
                  "0.000334001028277135",
                  "192",
                  "1.9682697025248057",
                  "0.5636992559711934",
                  "3",
                  "29",
                  "1.938225944277364e-05",
                  "PRUNED"
                ],
                [
                  "63",
                  "63",
                  "0.8776653339996668",
                  "[160, 160]",
                  "0.10014458092052947",
                  "5",
                  "0.03727725169411202",
                  "0.0003162010110229582",
                  "160",
                  "0.5503811429974375",
                  "0.25826287295220657",
                  "2",
                  "15",
                  "0.0007715983055977928",
                  "PRUNED"
                ],
                [
                  "233",
                  "233",
                  "0.8756484722782587",
                  "[128, 128]",
                  "0.15130423794212897",
                  "6",
                  "0.05246877653423748",
                  "0.0005197021282255286",
                  "128",
                  "1.02598902754174",
                  "0.24284630211701488",
                  "3",
                  "24",
                  "0.0001464189301333976",
                  "PRUNED"
                ],
                [
                  "57",
                  "57",
                  "0.8753485142005729",
                  "[64, 64]",
                  "0.2800536213315282",
                  "7",
                  "0.04557220618381384",
                  "0.000968320916799774",
                  "32",
                  "1.8951236648806233",
                  "0.2751346074856642",
                  "2",
                  "45",
                  "6.312049868026083e-05",
                  "PRUNED"
                ],
                [
                  "177",
                  "177",
                  "0.8745702419540241",
                  "[160, 160]",
                  "0.11390120002649529",
                  "7",
                  "0.05014941366430008",
                  "0.0003390126239217068",
                  "160",
                  "0.5988087145997916",
                  "0.5551254649183723",
                  "3",
                  "30",
                  "2.091148147277927e-05",
                  "PRUNED"
                ],
                [
                  "44",
                  "44",
                  "0.873991646290659",
                  "[128, 128]",
                  "0.11839181452625538",
                  "7",
                  "0.05234385807237794",
                  "0.0003756818974155998",
                  "160",
                  "0.8244142210167589",
                  "0.24255231572062294",
                  "4",
                  "47",
                  "0.00031076432419254314",
                  "PRUNED"
                ],
                [
                  "148",
                  "148",
                  "0.8724993326750492",
                  "[128, 128]",
                  "0.1251727674143717",
                  "4",
                  "0.032469206924901704",
                  "0.0004923569682624076",
                  "128",
                  "0.8683335892052861",
                  "0.22864535336905026",
                  "3",
                  "17",
                  "2.3569399471781697e-05",
                  "PRUNED"
                ],
                [
                  "114",
                  "114",
                  "0.8701621302509075",
                  "[160, 160]",
                  "0.13331441004776876",
                  "6",
                  "0.032126437051936",
                  "0.00031024944096711993",
                  "160",
                  "0.7024374408010848",
                  "0.2925685873066744",
                  "4",
                  "35",
                  "1.9505677035326514e-05",
                  "PRUNED"
                ],
                [
                  "152",
                  "152",
                  "0.8695029744094142",
                  "[160, 160]",
                  "0.16074359454644407",
                  "7",
                  "0.03376751231436991",
                  "0.0007590942291069164",
                  "192",
                  "1.2189672275320476",
                  "0.2549375834068204",
                  "4",
                  "30",
                  "8.423929395149723e-06",
                  "PRUNED"
                ]
              ],
              "shape": {
                "columns": 14,
                "rows": 300
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>number</th>\n",
              "      <th>value</th>\n",
              "      <th>params_conv_filters</th>\n",
              "      <th>params_dropout</th>\n",
              "      <th>params_early_stop_patience</th>\n",
              "      <th>params_label_smoothing</th>\n",
              "      <th>params_lr</th>\n",
              "      <th>params_lstm_units</th>\n",
              "      <th>params_max_grad_norm</th>\n",
              "      <th>params_scheduler_factor</th>\n",
              "      <th>params_scheduler_patience</th>\n",
              "      <th>params_search_epochs</th>\n",
              "      <th>params_weight_decay</th>\n",
              "      <th>state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>223</td>\n",
              "      <td>0.984681</td>\n",
              "      <td>[128, 128]</td>\n",
              "      <td>0.117753</td>\n",
              "      <td>6</td>\n",
              "      <td>0.034647</td>\n",
              "      <td>0.000506</td>\n",
              "      <td>128</td>\n",
              "      <td>1.067741</td>\n",
              "      <td>0.212087</td>\n",
              "      <td>3</td>\n",
              "      <td>23</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>0.984066</td>\n",
              "      <td>[128, 128]</td>\n",
              "      <td>0.107198</td>\n",
              "      <td>6</td>\n",
              "      <td>0.051445</td>\n",
              "      <td>0.000302</td>\n",
              "      <td>160</td>\n",
              "      <td>0.955732</td>\n",
              "      <td>0.241649</td>\n",
              "      <td>3</td>\n",
              "      <td>37</td>\n",
              "      <td>0.000831</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>122</td>\n",
              "      <td>0.983217</td>\n",
              "      <td>[160, 160]</td>\n",
              "      <td>0.114202</td>\n",
              "      <td>7</td>\n",
              "      <td>0.051782</td>\n",
              "      <td>0.000335</td>\n",
              "      <td>160</td>\n",
              "      <td>1.155704</td>\n",
              "      <td>0.349190</td>\n",
              "      <td>4</td>\n",
              "      <td>29</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>26</td>\n",
              "      <td>0.982091</td>\n",
              "      <td>[128, 128]</td>\n",
              "      <td>0.104526</td>\n",
              "      <td>7</td>\n",
              "      <td>0.035019</td>\n",
              "      <td>0.000367</td>\n",
              "      <td>160</td>\n",
              "      <td>0.725364</td>\n",
              "      <td>0.313477</td>\n",
              "      <td>3</td>\n",
              "      <td>25</td>\n",
              "      <td>0.000659</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>0.979995</td>\n",
              "      <td>[160, 160]</td>\n",
              "      <td>0.100988</td>\n",
              "      <td>6</td>\n",
              "      <td>0.030958</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>160</td>\n",
              "      <td>0.806692</td>\n",
              "      <td>0.255116</td>\n",
              "      <td>2</td>\n",
              "      <td>17</td>\n",
              "      <td>0.000596</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>196</td>\n",
              "      <td>0.635553</td>\n",
              "      <td>[48, 96]</td>\n",
              "      <td>0.123893</td>\n",
              "      <td>4</td>\n",
              "      <td>0.044955</td>\n",
              "      <td>0.000390</td>\n",
              "      <td>160</td>\n",
              "      <td>1.114788</td>\n",
              "      <td>0.271237</td>\n",
              "      <td>4</td>\n",
              "      <td>19</td>\n",
              "      <td>0.000130</td>\n",
              "      <td>PRUNED</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>264</th>\n",
              "      <td>264</td>\n",
              "      <td>0.628963</td>\n",
              "      <td>[128, 128]</td>\n",
              "      <td>0.340786</td>\n",
              "      <td>7</td>\n",
              "      <td>0.070958</td>\n",
              "      <td>0.000475</td>\n",
              "      <td>160</td>\n",
              "      <td>0.598498</td>\n",
              "      <td>0.306801</td>\n",
              "      <td>2</td>\n",
              "      <td>41</td>\n",
              "      <td>0.000051</td>\n",
              "      <td>PRUNED</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>50</td>\n",
              "      <td>0.618562</td>\n",
              "      <td>[64, 32]</td>\n",
              "      <td>0.291972</td>\n",
              "      <td>5</td>\n",
              "      <td>0.038385</td>\n",
              "      <td>0.000338</td>\n",
              "      <td>64</td>\n",
              "      <td>0.761416</td>\n",
              "      <td>0.206530</td>\n",
              "      <td>4</td>\n",
              "      <td>22</td>\n",
              "      <td>0.000166</td>\n",
              "      <td>PRUNED</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>0.614011</td>\n",
              "      <td>[64, 64]</td>\n",
              "      <td>0.315921</td>\n",
              "      <td>5</td>\n",
              "      <td>0.007548</td>\n",
              "      <td>0.000305</td>\n",
              "      <td>64</td>\n",
              "      <td>1.661958</td>\n",
              "      <td>0.491541</td>\n",
              "      <td>3</td>\n",
              "      <td>31</td>\n",
              "      <td>0.000216</td>\n",
              "      <td>PRUNED</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>0.600855</td>\n",
              "      <td>[48, 48]</td>\n",
              "      <td>0.258843</td>\n",
              "      <td>8</td>\n",
              "      <td>0.094462</td>\n",
              "      <td>0.000649</td>\n",
              "      <td>160</td>\n",
              "      <td>1.405005</td>\n",
              "      <td>0.453060</td>\n",
              "      <td>5</td>\n",
              "      <td>46</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>PRUNED</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>300 rows \u00d7 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     number     value params_conv_filters  params_dropout  \\\n",
              "223     223  0.984681          [128, 128]        0.117753   \n",
              "23       23  0.984066          [128, 128]        0.107198   \n",
              "122     122  0.983217          [160, 160]        0.114202   \n",
              "26       26  0.982091          [128, 128]        0.104526   \n",
              "21       21  0.979995          [160, 160]        0.100988   \n",
              "..      ...       ...                 ...             ...   \n",
              "196     196  0.635553            [48, 96]        0.123893   \n",
              "264     264  0.628963          [128, 128]        0.340786   \n",
              "50       50  0.618562            [64, 32]        0.291972   \n",
              "12       12  0.614011            [64, 64]        0.315921   \n",
              "6         6  0.600855            [48, 48]        0.258843   \n",
              "\n",
              "     params_early_stop_patience  params_label_smoothing  params_lr  \\\n",
              "223                           6                0.034647   0.000506   \n",
              "23                            6                0.051445   0.000302   \n",
              "122                           7                0.051782   0.000335   \n",
              "26                            7                0.035019   0.000367   \n",
              "21                            6                0.030958   0.000307   \n",
              "..                          ...                     ...        ...   \n",
              "196                           4                0.044955   0.000390   \n",
              "264                           7                0.070958   0.000475   \n",
              "50                            5                0.038385   0.000338   \n",
              "12                            5                0.007548   0.000305   \n",
              "6                             8                0.094462   0.000649   \n",
              "\n",
              "     params_lstm_units  params_max_grad_norm  params_scheduler_factor  \\\n",
              "223                128              1.067741                 0.212087   \n",
              "23                 160              0.955732                 0.241649   \n",
              "122                160              1.155704                 0.349190   \n",
              "26                 160              0.725364                 0.313477   \n",
              "21                 160              0.806692                 0.255116   \n",
              "..                 ...                   ...                      ...   \n",
              "196                160              1.114788                 0.271237   \n",
              "264                160              0.598498                 0.306801   \n",
              "50                  64              0.761416                 0.206530   \n",
              "12                  64              1.661958                 0.491541   \n",
              "6                  160              1.405005                 0.453060   \n",
              "\n",
              "     params_scheduler_patience  params_search_epochs  params_weight_decay  \\\n",
              "223                          3                    23             0.000001   \n",
              "23                           3                    37             0.000831   \n",
              "122                          4                    29             0.000030   \n",
              "26                           3                    25             0.000659   \n",
              "21                           2                    17             0.000596   \n",
              "..                         ...                   ...                  ...   \n",
              "196                          4                    19             0.000130   \n",
              "264                          2                    41             0.000051   \n",
              "50                           4                    22             0.000166   \n",
              "12                           3                    31             0.000216   \n",
              "6                            5                    46             0.000005   \n",
              "\n",
              "        state  \n",
              "223  COMPLETE  \n",
              "23   COMPLETE  \n",
              "122  COMPLETE  \n",
              "26   COMPLETE  \n",
              "21   COMPLETE  \n",
              "..        ...  \n",
              "196    PRUNED  \n",
              "264    PRUNED  \n",
              "50     PRUNED  \n",
              "12     PRUNED  \n",
              "6      PRUNED  \n",
              "\n",
              "[300 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import optuna\n",
        "\n",
        "# ============================\n",
        "# 1) Objective per Optuna\n",
        "# ============================\n",
        "def objective(trial):\n",
        "\n",
        "    # --- spazio degli iperparametri (adattalo come vuoi) ---\n",
        "    conv_filters = trial.suggest_categorical(\n",
        "        \"conv_filters\",\n",
        "        [\n",
        "            [160, 160],\n",
        "            [48, 48],\n",
        "            [64, 64],\n",
        "            [48, 96],\n",
        "            [64, 128],\n",
        "            [64, 32],\n",
        "            [128, 128],\n",
        "            [128,64]\n",
        "        ]\n",
        "    )\n",
        "    lstm_units = trial.suggest_categorical(\"lstm_units\", [32,64, 128, 160, 192])\n",
        "\n",
        "    dropout = trial.suggest_float(\"dropout\", 0.10, 0.40)\n",
        "    lr = trial.suggest_float(\"lr\", 3e-4, 1e-3, log=True)\n",
        "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
        "    label_smoothing = trial.suggest_float(\"label_smoothing\", 0.0, 0.15)\n",
        "\n",
        "    scheduler_factor = trial.suggest_float(\"scheduler_factor\", 0.2, 0.6)\n",
        "    scheduler_patience = trial.suggest_int(\"scheduler_patience\", 2, 5)\n",
        "\n",
        "    early_stop_patience = trial.suggest_int(\"early_stop_patience\", 4, 8)\n",
        "    max_grad_norm = trial.suggest_float(\"max_grad_norm\", 0.5, 2.0)\n",
        "\n",
        "    # puoi anche far scegliere a Optuna il numero di epoche di \"search\"\n",
        "    epochs_to_run = trial.suggest_int(\"search_epochs\", 15, 50)\n",
        "\n",
        "    # ============================\n",
        "    # 2) Modello + training loop\n",
        "    # ============================\n",
        "    model_gs = ConvLSTMClassifier(\n",
        "        input_size=n_features,\n",
        "        num_classes=n_classes,\n",
        "        conv_filters=conv_filters,\n",
        "        lstm_units=lstm_units,\n",
        "        dropout=dropout\n",
        "    ).to(device)\n",
        "\n",
        "    criterion_gs = WeightedLabelSmoothingCE(\n",
        "        class_weights=class_weights_tensor,\n",
        "        smoothing=label_smoothing\n",
        "    )\n",
        "\n",
        "    optimizer_gs = AdamW(\n",
        "        model_gs.parameters(),\n",
        "        lr=lr,\n",
        "        weight_decay=weight_decay\n",
        "    )\n",
        "\n",
        "    scheduler_gs = ReduceLROnPlateau(\n",
        "        optimizer_gs,\n",
        "        mode='max',\n",
        "        factor=scheduler_factor,\n",
        "        patience=scheduler_patience\n",
        "    )\n",
        "\n",
        "    best_f1_cfg = -np.inf\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(epochs_to_run):\n",
        "        train_loss, train_f1 = train_epoch(\n",
        "            model_gs, train_loader, criterion_gs, optimizer_gs, device, max_grad_norm\n",
        "        )\n",
        "        val_loss, val_f1, _, _ = eval_epoch(\n",
        "            model_gs, val_loader, criterion_gs, device\n",
        "        )\n",
        "        scheduler_gs.step(val_f1)\n",
        "\n",
        "        '''print(\n",
        "            f\"  Trial {trial.number:03d} | \"\n",
        "            f\"Epoch {epoch+1:02d}/{epochs_to_run} | \"\n",
        "            f\"Train F1: {train_f1:.4f} | Val F1: {val_f1:.4f}\",\n",
        "            end=\"\\r\"\n",
        "        )'''\n",
        "\n",
        "        # per Optuna: log dello stato intermedio (utile per pruning)\n",
        "        trial.report(val_f1, epoch)\n",
        "\n",
        "        # pruning: se il trial va male, lo stoppa prima\n",
        "        if trial.should_prune():\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "            raise optuna.TrialPruned()\n",
        "\n",
        "        # early stopping \"classico\"\n",
        "        if val_f1 > best_f1_cfg:\n",
        "            best_f1_cfg = val_f1\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= early_stop_patience:\n",
        "                break\n",
        "\n",
        "    print()  # newline\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # Optuna massimizza questo\n",
        "    return best_f1_cfg\n",
        "\n",
        "\n",
        "# ============================\n",
        "# 3) Lancio dello studio Optuna\n",
        "# ============================\n",
        "n_trials = 300  # quante combinazioni vuoi provare\n",
        "\n",
        "study = optuna.create_study(\n",
        "    direction=\"maximize\",\n",
        "    study_name=\"conv_lstm_opt\"\n",
        ")\n",
        "\n",
        "study.optimize(objective, n_trials=n_trials)\n",
        "\n",
        "# ============================\n",
        "# 4) Risultati e tabella tipo grid_search_df\n",
        "# ============================\n",
        "print(\"\\n\ud83c\udfc1 Optuna terminato\")\n",
        "print(f\"\ud83d\udd1d Best F1 val: {study.best_value:.4f}\")\n",
        "print(\"\ud83d\udd27 Best params:\")\n",
        "for k, v in study.best_params.items():\n",
        "    print(f\"   {k}: {v}\")\n",
        "\n",
        "# dataframe con tutti i trial, simile al tuo grid_search_df\n",
        "optuna_df = study.trials_dataframe(attrs=(\"number\", \"value\", \"params\", \"state\"))\n",
        "optuna_df = optuna_df.sort_values(by=\"value\", ascending=False)\n",
        "display(optuna_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\\n",
        "## \ud83c\udfaf Ensemble: Selezione Automatica dai Migliori Trial Optuna\\n",
        "\\n",
        "Ora selezioniamo i migliori N modelli dai trial di Optuna e creiamo un ensemble."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# ============================\\n",
        "# Selezione dei migliori N trial\\n",
        "# ============================\\n",
        "import gc\\n",
        "from copy import deepcopy\\n",
        "from scipy.special import softmax\\n",
        "\\n",
        "# Numero di modelli da includere nell'ensemble\\n",
        "N_MODELS_ENSEMBLE = 9\\n",
        "\\n",
        "# Ottieni i migliori trial ordinati per F1\\n",
        "trials_df = study.trials_dataframe(attrs=('number', 'value', 'params', 'state'))\\n",
        "trials_df = trials_df[trials_df['state'] == 'COMPLETE']\\n",
        "trials_df = trials_df.sort_values(by='value', ascending=False)\\n",
        "\\n",
        "# Seleziona i top N\\n",
        "best_trials = trials_df.head(N_MODELS_ENSEMBLE)\\n",
        "\\n",
        "print(f\"\\n\ud83d\udcca Selezionati i migliori {N_MODELS_ENSEMBLE} trial da Optuna:\")\\n",
        "print(\"=\"*70)\\n",
        "for idx, row in best_trials.iterrows():\\n",
        "    print(f\"Trial {row['number']:3d}: F1 = {row['value']:.4f}\")\\n",
        "print(\"=\"*70)\\n",
        "\\n",
        "print(f\"\\n\ud83d\udd0d Range F1 scores: {best_trials['value'].min():.4f} - {best_trials['value'].max():.4f}\")\\n",
        "print(f\"   Media F1: {best_trials['value'].mean():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# ============================\\n",
        "# Training ensemble models\\n",
        "# ============================\\n",
        "\\n",
        "def train_model_from_trial(trial_params, trial_number, X_tr, y_tr, X_val, y_val, \\n",
        "                          device, class_weights_tensor, n_features, n_classes):\\n",
        "    \\\"\\\"\\\"Train a single model with parameters from Optuna trial.\\\"\\\"\\\"\\n",
        "    \\n",
        "    print(f\"\\\\n{'='*60}\")\\n",
        "    print(f\"  Training model from Trial {trial_number}\")\\n",
        "    print(f\"{'='*60}\")\\n",
        "    \\n",
        "    # Extract parameters\\n",
        "    conv_filters = trial_params['params_conv_filters']\\n",
        "    lstm_units = trial_params['params_lstm_units']\\n",
        "    dropout = trial_params['params_dropout']\\n",
        "    lr = trial_params['params_lr']\\n",
        "    weight_decay = trial_params['params_weight_decay']\\n",
        "    label_smoothing = trial_params['params_label_smoothing']\\n",
        "    scheduler_factor = trial_params['params_scheduler_factor']\\n",
        "    scheduler_patience = trial_params['params_scheduler_patience']\\n",
        "    early_stop_patience = trial_params['params_early_stop_patience']\\n",
        "    max_grad_norm = trial_params['params_max_grad_norm']\\n",
        "    max_epochs = trial_params['params_search_epochs']\\n",
        "    \\n",
        "    print(f\"  Config: conv={conv_filters}, lstm={lstm_units}, dropout={dropout:.3f}\")\\n",
        "    print(f\"  LR: {lr:.6f}, epochs: {max_epochs}\")\\n",
        "    \\n",
        "    # Create model\\n",
        "    model = ConvLSTMClassifier(\\n",
        "        input_size=n_features,\\n",
        "        num_classes=n_classes,\\n",
        "        conv_filters=conv_filters,\\n",
        "        lstm_units=lstm_units,\\n",
        "        dropout=dropout\\n",
        "    ).to(device)\\n",
        "    \\n",
        "    criterion = WeightedLabelSmoothingCE(\\n",
        "        class_weights=class_weights_tensor,\\n",
        "        smoothing=label_smoothing\\n",
        "    )\\n",
        "    \\n",
        "    optimizer = AdamW(\\n",
        "        model.parameters(),\\n",
        "        lr=lr,\\n",
        "        weight_decay=weight_decay\\n",
        "    )\\n",
        "    \\n",
        "    scheduler = ReduceLROnPlateau(\\n",
        "        optimizer,\\n",
        "        mode='max',\\n",
        "        factor=scheduler_factor,\\n",
        "        patience=scheduler_patience\\n",
        "    )\\n",
        "    \\n",
        "    # Training loop\\n",
        "    best_f1 = -np.inf\\n",
        "    best_state = None\\n",
        "    patience_counter = 0\\n",
        "    history = []\\n",
        "    \\n",
        "    for epoch in range(max_epochs):\\n",
        "        # Train\\n",
        "        train_loss, train_f1 = train_epoch(\\n",
        "            model, train_loader, criterion, optimizer, device, max_grad_norm\\n",
        "        )\\n",
        "        \\n",
        "        # Validate\\n",
        "        val_loss, val_f1, val_preds, val_labels = eval_epoch(\\n",
        "            model, val_loader, criterion, device\\n",
        "        )\\n",
        "        \\n",
        "        scheduler.step(val_f1)\\n",
        "        \\n",
        "        history.append({\\n",
        "            'epoch': epoch + 1,\\n",
        "            'train_loss': train_loss,\\n",
        "            'train_f1': train_f1,\\n",
        "            'val_loss': val_loss,\\n",
        "            'val_f1': val_f1\\n",
        "        })\\n",
        "        \\n",
        "        print(f\"  Epoch {epoch+1:02d}/{max_epochs} | \"\\n",
        "              f\"Train: loss={train_loss:.4f} F1={train_f1:.4f} | \"\\n",
        "              f\"Val: loss={val_loss:.4f} F1={val_f1:.4f}\")\\n",
        "        \\n",
        "        # Early stopping\\n",
        "        if val_f1 > best_f1:\\n",
        "            best_f1 = val_f1\\n",
        "            best_state = deepcopy(model.state_dict())\\n",
        "            patience_counter = 0\\n",
        "            print(f\"    \u2705 New best F1: {best_f1:.4f}\")\\n",
        "        else:\\n",
        "            patience_counter += 1\\n",
        "            if patience_counter >= early_stop_patience:\\n",
        "                print(f\"    \u23f9\ufe0f Early stopping at epoch {epoch+1}\")\\n",
        "                break\\n",
        "    \\n",
        "    # Restore best weights\\n",
        "    if best_state is not None:\\n",
        "        model.load_state_dict(best_state)\\n",
        "    \\n",
        "    print(f\"  Final best F1: {best_f1:.4f}\\\\n\")\\n",
        "    \\n",
        "    return model, best_f1, history\\n",
        "\\n",
        "\\n",
        "# Train all ensemble models\\n",
        "print(\"\\\\n\" + \"=\"*70)\\n",
        "print(\"\ud83d\ude80 TRAINING ENSEMBLE MODELS\")\\n",
        "print(\"=\"*70)\\n",
        "\\n",
        "ensemble_models = []\\n",
        "ensemble_f1_scores = []\\n",
        "ensemble_histories = []\\n",
        "ensemble_trial_numbers = []\\n",
        "\\n",
        "for idx, row in best_trials.iterrows():\\n",
        "    trial_number = int(row['number'])\\n",
        "    \\n",
        "    model, f1_score, history = train_model_from_trial(\\n",
        "        row, trial_number, X_tr, y_tr, X_val, y_val,\\n",
        "        device, class_weights_tensor, n_features, n_classes\\n",
        "    )\\n",
        "    \\n",
        "    ensemble_models.append(model)\\n",
        "    ensemble_f1_scores.append(f1_score)\\n",
        "    ensemble_histories.append(history)\\n",
        "    ensemble_trial_numbers.append(trial_number)\\n",
        "    \\n",
        "    gc.collect()\\n",
        "    if torch.cuda.is_available():\\n",
        "        torch.cuda.empty_cache()\\n",
        "\\n",
        "print(\"\\\\n\" + \"=\"*70)\\n",
        "print(f\"\u2705 Training completato! {len(ensemble_models)} modelli allenati.\")\\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# ============================\\n",
        "# EWA Weighting\\n",
        "# ============================\\n",
        "\\n",
        "ensemble_f1_array = np.array(ensemble_f1_scores)\\n",
        "\\n",
        "print(\"\\\\n\" + \"=\"*70)\\n",
        "print(\"\ud83d\udcca VALUTAZIONE ENSEMBLE E CALCOLO PESI EWA\")\\n",
        "print(\"=\"*70)\\n",
        "\\n",
        "print(\"\\\\nF1 scores dei singoli modelli:\")\\n",
        "for i, (trial_num, f1) in enumerate(zip(ensemble_trial_numbers, ensemble_f1_scores)):\\n",
        "    print(f\"  Modello {i} (Trial {trial_num}): F1 = {f1:.4f}\")\\n",
        "\\n",
        "# EWA weights\\n",
        "eta = 15.0\\n",
        "losses = 1.0 - ensemble_f1_array\\n",
        "raw_weights = np.exp(-eta * losses)\\n",
        "weights = raw_weights / raw_weights.sum()\\n",
        "\\n",
        "print(f\"\\\\nPesi EWA (eta={eta}):\")\\n",
        "for i, (trial_num, w) in enumerate(zip(ensemble_trial_numbers, weights)):\\n",
        "    print(f\"  Modello {i} (Trial {trial_num}): peso = {w:.4f}\")\\n",
        "\\n",
        "print(f\"\\\\nStatistiche:\")\\n",
        "print(f\"  F1 medio singoli: {ensemble_f1_array.mean():.4f}\")\\n",
        "print(f\"  F1 min: {ensemble_f1_array.min():.4f}\")\\n",
        "print(f\"  F1 max: {ensemble_f1_array.max():.4f}\")\\n",
        "print(f\"  Somma pesi: {weights.sum():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# ============================\\n",
        "# Ensemble Prediction Functions\\n",
        "# ============================\\n",
        "\\n",
        "@torch.no_grad()\\n",
        "def predict_proba_batch(model, X_batch, device):\\n",
        "    \\\"\\\"\\\"Get probability predictions for a batch.\\\"\\\"\\\"\\n",
        "    model.eval()\\n",
        "    X_tensor = torch.FloatTensor(X_batch).to(device)\\n",
        "    logits = model(X_tensor)\\n",
        "    probs = F.softmax(logits, dim=1)\\n",
        "    return probs.cpu().numpy()\\n",
        "\\n",
        "\\n",
        "def ensemble_predict_weighted(models, X_data, weights, device, batch_size=256):\\n",
        "    \\\"\\\"\\\"Make weighted ensemble predictions.\\\"\\\"\\\"\\n",
        "    n_samples = X_data.shape[0]\\n",
        "    n_classes = len(label_encoder.classes_)\\n",
        "    \\n",
        "    # Initialize weighted probabilities\\n",
        "    weighted_probs = np.zeros((n_samples, n_classes))\\n",
        "    \\n",
        "    # Accumulate weighted predictions from each model\\n",
        "    for model, weight in zip(models, weights):\\n",
        "        model_probs = np.zeros((n_samples, n_classes))\\n",
        "        \\n",
        "        # Process in batches\\n",
        "        for i in range(0, n_samples, batch_size):\\n",
        "            batch_end = min(i + batch_size, n_samples)\\n",
        "            X_batch = X_data[i:batch_end]\\n",
        "            batch_probs = predict_proba_batch(model, X_batch, device)\\n",
        "            model_probs[i:batch_end] = batch_probs\\n",
        "        \\n",
        "        weighted_probs += weight * model_probs\\n",
        "    \\n",
        "    # Apply softmax and get predictions\\n",
        "    weighted_probs = softmax(weighted_probs, axis=1)\\n",
        "    predictions = np.argmax(weighted_probs, axis=1)\\n",
        "    \\n",
        "    return predictions, weighted_probs\\n",
        "\\n",
        "\\n",
        "print(\"\u2705 Funzioni di predizione ensemble definite\")\\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# ============================\\n",
        "# Valutazione Ensemble su Validation\\n",
        "# ============================\\n",
        "\\n",
        "print(\"\\\\n\" + \"=\"*70)\\n",
        "print(\"\ud83e\uddea VALUTAZIONE ENSEMBLE SU VALIDATION SET\")\\n",
        "print(\"=\"*70)\\n",
        "\\n",
        "# Ensemble predictions\\n",
        "y_val_pred_ensemble, y_val_probs_ensemble = ensemble_predict_weighted(\\n",
        "    ensemble_models, X_val, weights, device\\n",
        ")\\n",
        "\\n",
        "# Calculate metrics\\n",
        "ensemble_f1 = f1_score(y_val, y_val_pred_ensemble, average='macro')\\n",
        "ensemble_acc = (y_val_pred_ensemble == y_val).mean()\\n",
        "\\n",
        "print(f\"\\\\n\ud83d\udcca Risultati Ensemble:\")\\n",
        "print(f\"  F1 Score (macro): {ensemble_f1:.4f}\")\\n",
        "print(f\"  Accuracy: {ensemble_acc:.4f}\")\\n",
        "print(f\"\\\\n  Confronto con singoli modelli:\")\\n",
        "print(f\"    F1 medio singoli: {ensemble_f1_array.mean():.4f}\")\\n",
        "print(f\"    F1 best singolo: {ensemble_f1_array.max():.4f}\")\\n",
        "print(f\"    Miglioramento su media: {(ensemble_f1 - ensemble_f1_array.mean())*100:.2f}%\")\\n",
        "print(f\"    Miglioramento su best: {(ensemble_f1 - ensemble_f1_array.max())*100:.2f}%\")\\n",
        "\\n",
        "# Classification report\\n",
        "print(\"\\\\n\ud83d\udccb Classification Report (Ensemble):\")\\n",
        "print(classification_report(y_val, y_val_pred_ensemble, \\n",
        "                          target_names=label_encoder.classes_, \\n",
        "                          digits=4))\\n",
        "\\n",
        "# Confusion matrix\\n",
        "print(\"\\\\n\ud83d\udcca Confusion Matrix:\")\\n",
        "cm = confusion_matrix(y_val, y_val_pred_ensemble)\\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# ============================\\n",
        "# Test Prediction con Ensemble\\n",
        "# ============================\\n",
        "\\n",
        "print(\"\\\\n\" + \"=\"*70)\\n",
        "print(\"\ud83d\udd2e PREDIZIONE TEST CON ENSEMBLE\")\\n",
        "print(\"=\"*70)\\n",
        "\\n",
        "# Load and preprocess test data (gi\u00e0 fatto nelle celle precedenti dal notebook originale)\\n",
        "# X_test dovrebbe gi\u00e0 essere caricato\\n",
        "\\n",
        "test_sample_indices = X_test['sample_index'].unique()\\n",
        "sample_predictions = {}\\n",
        "\\n",
        "for sid in tqdm(test_sample_indices, desc='Predicting with ensemble'):\\n",
        "    # Create windows\\n",
        "    windows = create_windows(X_test_proc, sid, WINDOW_SIZE, WINDOW_STRIDE)\\n",
        "    \\n",
        "    if len(windows) > 0:\\n",
        "        X_sample = np.array(windows, dtype=np.float32)\\n",
        "        X_sample = scaler.transform(\\n",
        "            X_sample.reshape(-1, X_sample.shape[-1])\\n",
        "        ).reshape(X_sample.shape)\\n",
        "        \\n",
        "        # Ensemble prediction\\n",
        "        preds, probs = ensemble_predict_weighted(\\n",
        "            ensemble_models, X_sample, weights, device, batch_size=256\\n",
        "        )\\n",
        "        \\n",
        "        # Average probabilities across windows\\n",
        "        avg_probs = probs.mean(axis=0)\\n",
        "        final_pred = np.argmax(avg_probs)\\n",
        "        \\n",
        "        sample_predictions[sid] = final_pred\\n",
        "\\n",
        "print(f\"\\\\n\u2705 Predizioni completate per {len(sample_predictions)} campioni\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# ============================\\n",
        "# Creazione Submission\\n",
        "# ============================\\n",
        "\\n",
        "submission_data = []\\n",
        "for sid in sorted(sample_predictions.keys()):\\n",
        "    pred_class = sample_predictions[sid]\\n",
        "    pred_label = label_encoder.classes_[pred_class]\\n",
        "    submission_data.append({\\n",
        "        'sample_index': sid,\\n",
        "        'label': pred_label\\n",
        "    })\\n",
        "\\n",
        "submission = pd.DataFrame(submission_data)\\n",
        "submission.to_csv('submission_optuna_ensemble.csv', index=False)\\n",
        "\\n",
        "print('\u2705 Submission created!')\\n",
        "print(f'   File: submission_optuna_ensemble.csv')\\n",
        "print(f'   Shape: {submission.shape}')\\n",
        "print(f'\\\\n\ud83d\udcca Predicted label distribution:')\\n",
        "print(submission['label'].value_counts())\\n",
        "\\n",
        "print(\"\\\\n\" + \"=\"*70)\\n",
        "print(\"\ud83c\udf89 PIPELINE COMPLETATA CON SUCCESSO!\")\\n",
        "print(\"=\"*70)\\n",
        "print(f\"\\\\n\ud83d\udcc8 Riepilogo:\")\\n",
        "print(f\"  - {len(ensemble_models)} modelli nell'ensemble (dai migliori trial Optuna)\")\\n",
        "print(f\"  - F1 ensemble su validation: {ensemble_f1:.4f}\")\\n",
        "print(f\"  - Miglioramento rispetto al best single model: {(ensemble_f1 - ensemble_f1_array.max())*100:.2f}%\")\\n",
        "print(f\"  - File submission: submission_optuna_ensemble.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# ============================\\n",
        "# Visualizzazioni\\n",
        "# ============================\\n",
        "\\n",
        "import matplotlib.pyplot as plt\\n",
        "import seaborn as sns\\n",
        "\\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\\n",
        "\\n",
        "# Plot 1: F1 scores dei modelli\\n",
        "ax1 = axes[0]\\n",
        "x_pos = np.arange(len(ensemble_f1_scores))\\n",
        "ax1.bar(x_pos, ensemble_f1_scores, alpha=0.7, label='Modelli individuali')\\n",
        "ax1.axhline(y=ensemble_f1, color='r', linestyle='--', linewidth=2, \\n",
        "           label=f'Ensemble F1: {ensemble_f1:.4f}')\\n",
        "ax1.axhline(y=ensemble_f1_array.mean(), color='g', linestyle=':', linewidth=2,\\n",
        "           label=f'Media F1: {ensemble_f1_array.mean():.4f}')\\n",
        "ax1.set_xlabel('Modello Index')\\n",
        "ax1.set_ylabel('F1 Score (macro)')\\n",
        "ax1.set_title('F1 Scores: Modelli Individuali vs Ensemble')\\n",
        "ax1.legend()\\n",
        "ax1.grid(True, alpha=0.3)\\n",
        "\\n",
        "# Add trial numbers as labels\\n",
        "ax1.set_xticks(x_pos)\\n",
        "ax1.set_xticklabels([f'T{tn}' for tn in ensemble_trial_numbers], rotation=45)\\n",
        "\\n",
        "# Plot 2: Pesi EWA\\n",
        "ax2 = axes[1]\\n",
        "ax2.bar(x_pos, weights, alpha=0.7, color='orange')\\n",
        "ax2.set_xlabel('Modello Index')\\n",
        "ax2.set_ylabel('Peso EWA')\\n",
        "ax2.set_title(f'Pesi EWA (\u03b7={eta})')\\n",
        "ax2.grid(True, alpha=0.3)\\n",
        "ax2.set_xticks(x_pos)\\n",
        "ax2.set_xticklabels([f'T{tn}' for tn in ensemble_trial_numbers], rotation=45)\\n",
        "\\n",
        "plt.tight_layout()\\n",
        "plt.savefig('ensemble_optuna_results.png', dpi=150, bbox_inches='tight')\\n",
        "plt.show()\\n",
        "\\n",
        "print(\"\\\\n\u2705 Grafici salvati in 'ensemble_optuna_results.png'\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}