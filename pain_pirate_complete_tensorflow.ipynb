{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# ğŸ´â€â˜ ï¸ Pain Pirate Analysis - Pipeline Completa TensorFlow\n",
    "\n",
    "Pipeline end-to-end con **tutte le 7 ADVICE del professore integrate nel codice**.\n",
    "\n",
    "## Dataset\n",
    "- **pirate_pain_train.csv**: 105,760 righe = 661 samples Ã— 160 timesteps\n",
    "- **pirate_pain_train_labels.csv**: 661 labels (no_pain, low_pain, high_pain)\n",
    "- **Features**: 38 (4 pain_survey + 3 categorical + 31 joints)\n",
    "- **Classe dominante**: no_pain (511) - dataset **sbilanciato**!\n",
    "\n",
    "## ADVICE Integrate\n",
    "1. âœ… **11/11 - Autocorrelazione**: Window size basata sui dati\n",
    "2. âœ… **12/11 - Time Features**: Encoding ciclico temporale\n",
    "3. âœ… **13/11 - Conv1D+LSTM**: Architettura ibrida\n",
    "4. âœ… **10/11 - Gradient Clipping**: Stabilizza training\n",
    "5. âœ… **09/11 - Label Smoothing**: Loss con smoothing\n",
    "6. âœ… **08/11 - Class Weighting**: Gestisce sbilanciamento\n",
    "7. âœ… **07/11 - Embeddings**: Features categoriche\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.16.2\n",
      "GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "âœ… Environment ready!\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# TensorFlow/Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "# Stats and ML\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Set seeds\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(f'TensorFlow: {tf.__version__}')\n",
    "print(f'GPU: {tf.config.list_physical_devices(\"GPU\")}')\n",
    "print('âœ… Environment ready!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_header",
   "metadata": {},
   "source": [
    "## 1. Caricamento Dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Dataset Shape:\n",
      "  Features: (105760, 40)\n",
      "  Labels: (661, 2)\n",
      "  Samples: 661\n",
      "  Timesteps/sample: 160\n",
      "\n",
      "ğŸ“‹ Features: 4 pain_survey + 3 categorical + 31 joints\n",
      "\n",
      "ğŸ·ï¸ Labels (IMBALANCED - need class weighting):\n",
      "  no_pain: 511 (77.3%)\n",
      "  low_pain: 94 (14.2%)\n",
      "  high_pain: 56 (8.5%)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "X_train = pd.read_csv('pirate_pain_train.csv')\n",
    "y_train = pd.read_csv('pirate_pain_train_labels.csv')\n",
    "\n",
    "print('ğŸ“Š Dataset Shape:')\n",
    "print(f'  Features: {X_train.shape}')\n",
    "print(f'  Labels: {y_train.shape}')\n",
    "print(f'  Samples: {X_train[\"sample_index\"].nunique()}')\n",
    "print(f'  Timesteps/sample: {X_train.groupby(\"sample_index\").size().iloc[0]}')\n",
    "\n",
    "# Feature groups\n",
    "pain_survey_cols = [c for c in X_train.columns if 'pain_survey' in c]\n",
    "categorical_cols = ['n_legs', 'n_hands', 'n_eyes']\n",
    "joint_cols = [c for c in X_train.columns if 'joint_' in c]\n",
    "\n",
    "print(f'\\nğŸ“‹ Features: {len(pain_survey_cols)} pain_survey + {len(categorical_cols)} categorical + {len(joint_cols)} joints')\n",
    "\n",
    "# ADVICE 08/11: Check class imbalance\n",
    "print(f'\\nğŸ·ï¸ Labels (IMBALANCED - need class weighting):')\n",
    "for label, count in y_train['label'].value_counts().items():\n",
    "    print(f'  {label}: {count} ({100*count/len(y_train):.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "autocorr_header",
   "metadata": {},
   "source": [
    "## 2. ADVICE 11/11: Determinare WINDOW_SIZE\n",
    "\n",
    "*\"Its own echo, the series sings.\"*\n",
    "\n",
    "Usiamo autocorrelazione per scegliere window size basata sui dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "autocorr_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Analyzing autocorrelation...\n",
      "âœ… WINDOW_SIZE from autocorrelation: 40\n",
      "   STRIDE: 20\n",
      "ğŸ’¡ ADVICE 11/11: Data-driven window size!\n"
     ]
    }
   ],
   "source": [
    "# ADVICE 11/11: Analyze autocorrelation to determine optimal window\n",
    "print('ğŸ” Analyzing autocorrelation...')\n",
    "samples_analyze = X_train['sample_index'].unique()[:10]\n",
    "key_features = joint_cols[:6]\n",
    "\n",
    "optimal_lags = {}\n",
    "for feature in key_features:\n",
    "    sample_lags = []\n",
    "    for sid in samples_analyze:\n",
    "        data = X_train[X_train['sample_index']==sid][feature].values\n",
    "        if len(data) >= 50:\n",
    "            max_lags = min(len(data)//2-1, 80)\n",
    "            acf_vals = acf(data, nlags=max_lags)\n",
    "            sig_bound = 1.96/np.sqrt(len(data))\n",
    "            for lag in range(1, len(acf_vals)):\n",
    "                if abs(acf_vals[lag]) < sig_bound:\n",
    "                    sample_lags.append(lag)\n",
    "                    break\n",
    "            else:\n",
    "                sample_lags.append(max_lags)\n",
    "    if sample_lags:\n",
    "        optimal_lags[feature] = int(np.median(sample_lags))\n",
    "\n",
    "if optimal_lags:\n",
    "    suggested = int(np.median(list(optimal_lags.values())))\n",
    "    WINDOW_SIZE = max(min(suggested, 100), 40)\n",
    "else:\n",
    "    WINDOW_SIZE = 60\n",
    "\n",
    "WINDOW_STRIDE = WINDOW_SIZE // 2\n",
    "\n",
    "print(f'âœ… WINDOW_SIZE from autocorrelation: {WINDOW_SIZE}')\n",
    "print(f'   STRIDE: {WINDOW_STRIDE}')\n",
    "print(f'ğŸ’¡ ADVICE 11/11: Data-driven window size!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preproc_header",
   "metadata": {},
   "source": [
    "## 3. Preprocessing con ADVICE 07/11 e 12/11\n",
    "\n",
    "**ADVICE 07/11**: Map categorical per embeddings  \n",
    "**ADVICE 12/11**: Aggiungi time features ciclici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "preproc_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Preprocessing done:\n",
      "   - ADVICE 07/11: Categorical mapped\n",
      "   - ADVICE 12/11: Time features (sin, cos, norm) added\n",
      "   Shape: (105760, 43)\n"
     ]
    }
   ],
   "source": [
    "# ADVICE 07/11: Map categorical features\n",
    "cat_map = {\n",
    "    'n_legs': {'two': 0, 'one+peg_leg': 1},\n",
    "    'n_hands': {'two': 0, 'one+hook_hand': 1},\n",
    "    'n_eyes': {'two': 0, 'one+eye_patch': 1}\n",
    "}\n",
    "\n",
    "X_proc = X_train.copy()\n",
    "for col, mapping in cat_map.items():\n",
    "    X_proc[col] = X_proc[col].map(mapping).fillna(0).astype(int)\n",
    "\n",
    "# ADVICE 12/11: Add cyclical time features\n",
    "max_time = X_proc['time'].max()\n",
    "X_proc['time_sin'] = np.sin(2*np.pi*X_proc['time']/max_time)\n",
    "X_proc['time_cos'] = np.cos(2*np.pi*X_proc['time']/max_time)\n",
    "X_proc['time_norm'] = X_proc['time']/max_time\n",
    "\n",
    "print('âœ… Preprocessing done:')\n",
    "print('   - ADVICE 07/11: Categorical mapped')\n",
    "print('   - ADVICE 12/11: Time features (sin, cos, norm) added')\n",
    "print(f'   Shape: {X_proc.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "windows_header",
   "metadata": {},
   "source": [
    "## 4. Creazione Finestre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "windows_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Creating windows...\n",
      "âœ… Windows: (4627, 40, 41)\n",
      "   Labels: (4627,)\n",
      "âœ… Windows: (4627, 40, 41)\n",
      "   Labels: (4627,)\n"
     ]
    }
   ],
   "source": [
    "# Create sliding windows\n",
    "def create_windows(df, sample_idx, window_size, stride):\n",
    "    sample = df[df['sample_index']==sample_idx].sort_values('time')\n",
    "    feat_cols = [c for c in sample.columns if c not in ['sample_index','time']]\n",
    "    features = sample[feat_cols].values\n",
    "    \n",
    "    windows = []\n",
    "    for start in range(0, max(1, len(features)-window_size+1), stride):\n",
    "        end = min(start+window_size, len(features))\n",
    "        win = features[start:end]\n",
    "        if len(win) < window_size:\n",
    "            pad = np.zeros((window_size-len(win), win.shape[1]))\n",
    "            win = np.vstack([win, pad])\n",
    "        windows.append(win)\n",
    "    return windows\n",
    "\n",
    "print('ğŸ”„ Creating windows...')\n",
    "all_windows = []\n",
    "all_labels = []\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y_train['label'])\n",
    "\n",
    "for sid, label in zip(y_train['sample_index'], y_encoded):\n",
    "    wins = create_windows(X_proc, sid, WINDOW_SIZE, WINDOW_STRIDE)\n",
    "    all_windows.extend(wins)\n",
    "    all_labels.extend([label]*len(wins))\n",
    "\n",
    "X_windows = np.array(all_windows, dtype=np.float32)\n",
    "y_windows = np.array(all_labels, dtype=np.int32)\n",
    "\n",
    "print(f'âœ… Windows: {X_windows.shape}')\n",
    "print(f'   Labels: {y_windows.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "split_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Split: Train (3701, 40, 41), Val (926, 40, 41)\n",
      "\n",
      "âš–ï¸ ADVICE 08/11 - Class Weights:\n",
      "   high_pain: 3.929\n",
      "   low_pain: 2.345\n",
      "   no_pain: 0.431\n"
     ]
    }
   ],
   "source": [
    "# Split and normalize\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_windows, y_windows, test_size=0.2, random_state=SEED, stratify=y_windows\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_tr = scaler.fit_transform(X_tr.reshape(-1, X_tr.shape[-1])).reshape(X_tr.shape)\n",
    "X_val = scaler.transform(X_val.reshape(-1, X_val.shape[-1])).reshape(X_val.shape)\n",
    "\n",
    "print(f'ğŸ“Š Split: Train {X_tr.shape}, Val {X_val.shape}')\n",
    "\n",
    "# ADVICE 08/11: Compute class weights\n",
    "class_weights_array = compute_class_weight('balanced', classes=np.unique(y_tr), y=y_tr)\n",
    "class_weights_dict = {i: w for i, w in enumerate(class_weights_array)}\n",
    "\n",
    "print(f'\\nâš–ï¸ ADVICE 08/11 - Class Weights:')\n",
    "for i, w in class_weights_dict.items():\n",
    "    print(f'   {label_encoder.classes_[i]}: {w:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model_header",
   "metadata": {},
   "source": [
    "## 5. ADVICE 13/11: Conv1D + LSTM\n",
    "\n",
    "*\"A pattern in time, like a pattern in space it is.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "model_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ADVICE 13/11: Conv1D + LSTM created\n",
      "   Input: (40, 41)\n",
      "   Output: 3 classes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Conv_LSTM\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Conv_LSTM\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,936</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_3           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_4           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_5           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m41\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚         \u001b[38;5;34m7,936\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_3           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚        \u001b[38;5;34m12,352\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_4           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚       \u001b[38;5;34m197,632\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_5           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m1,024\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚        \u001b[38;5;34m16,448\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              â”‚           \u001b[38;5;34m195\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">236,099</span> (922.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m236,099\u001b[0m (922.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,331</span> (919.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m235,331\u001b[0m (919.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ADVICE 13/11: Build Conv1D + LSTM model\n",
    "def build_conv_lstm_model(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Conv1D blocks\n",
    "    x = layers.Conv1D(64, 3, padding='same', activation='relu')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling1D(2)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    x = layers.Conv1D(64, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling1D(2)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # LSTM\n",
    "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=False))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Classification\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=outputs, name='Conv_LSTM')\n",
    "\n",
    "n_features = X_tr.shape[2]\n",
    "n_classes = len(label_encoder.classes_)\n",
    "\n",
    "model = build_conv_lstm_model((WINDOW_SIZE, n_features), n_classes)\n",
    "\n",
    "print('âœ… ADVICE 13/11: Conv1D + LSTM created')\n",
    "print(f'   Input: ({WINDOW_SIZE}, {n_features})')\n",
    "print(f'   Output: {n_classes} classes')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "459e9655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom macro F1 metric so we can monitor validation F1 directly\n",
    "class MacroF1(keras.metrics.Metric):\n",
    "    def __init__(self, num_classes, name='macro_f1', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.true_positives = self.add_weight(shape=(num_classes,), initializer='zeros', name='tp')\n",
    "        self.false_positives = self.add_weight(shape=(num_classes,), initializer='zeros', name='fp')\n",
    "        self.false_negatives = self.add_weight(shape=(num_classes,), initializer='zeros', name='fn')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        if y_true.shape.rank > 1:\n",
    "            y_true_labels = tf.argmax(y_true, axis=-1)\n",
    "        else:\n",
    "            y_true_labels = tf.cast(y_true, tf.int32)\n",
    "        y_pred_labels = tf.argmax(y_pred, axis=-1)\n",
    "\n",
    "        y_true_one_hot = tf.one_hot(y_true_labels, depth=self.num_classes, dtype=tf.float32)\n",
    "        y_pred_one_hot = tf.one_hot(y_pred_labels, depth=self.num_classes, dtype=tf.float32)\n",
    "\n",
    "        if sample_weight is not None:\n",
    "            sample_weight = tf.cast(tf.reshape(sample_weight, [-1, 1]), tf.float32)\n",
    "            y_true_one_hot *= sample_weight\n",
    "            y_pred_one_hot *= sample_weight\n",
    "\n",
    "        tp = tf.reduce_sum(y_true_one_hot * y_pred_one_hot, axis=0)\n",
    "        fp = tf.reduce_sum((1.0 - y_true_one_hot) * y_pred_one_hot, axis=0)\n",
    "        fn = tf.reduce_sum(y_true_one_hot * (1.0 - y_pred_one_hot), axis=0)\n",
    "\n",
    "        self.true_positives.assign_add(tp)\n",
    "        self.false_positives.assign_add(fp)\n",
    "        self.false_negatives.assign_add(fn)\n",
    "\n",
    "    def result(self):\n",
    "        precision = self.true_positives / (self.true_positives + self.false_positives + tf.keras.backend.epsilon())\n",
    "        recall = self.true_positives / (self.true_positives + self.false_negatives + tf.keras.backend.epsilon())\n",
    "        f1 = 2.0 * precision * recall / (precision + recall + tf.keras.backend.epsilon())\n",
    "        return tf.reduce_mean(f1)\n",
    "\n",
    "    def reset_state(self):\n",
    "        for var in (self.true_positives, self.false_positives, self.false_negatives):\n",
    "            var.assign(tf.zeros_like(var))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grid_search_header",
   "metadata": {},
   "source": [
    "## 5.5. ğŸ” Grid Search per Ottimizzazione Iperparametri\n",
    "\n",
    "**Obiettivo**: Trovare automaticamente la combinazione di iperparametri che **massimizza F1 Macro Score**.\n",
    "\n",
    "Strategia:\n",
    "- Testa sistematicamente diverse combinazioni di iperparametri\n",
    "- **F1 Macro** come metrica obiettivo (metrica della challenge)\n",
    "- Le ADVICE (gradient clipping, class weighting) sono **sempre applicate**\n",
    "- Early stopping per efficienza\n",
    "\n",
    "**Nota**: Grid search puÃ² richiedere tempo. Per test rapidi, riduci il numero di combinazioni in `param_grid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grid_search",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Grid Search Configuration:\n",
      "   Parameters to test: ['conv_filters', 'lstm_units', 'dropout', 'learning_rate', 'label_smoothing', 'batch_size']\n",
      "   Total combinations: 64\n",
      "   Estimated time depends on n_jobs (parallel execution)\n",
      "\n",
      "âš™ï¸ Using 4 parallel workers (adjust max_jobs variable if needed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid search:   6%|â–‹         | 4/64 [00:00<00:02, 20.39it/s]2025-11-13 16:46:10.438827: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4\n",
      "2025-11-13 16:46:10.438854: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-11-13 16:46:10.438870: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.92 GB\n",
      "2025-11-13 16:46:10.438884: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-11-13 16:46:10.438894: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-11-13 16:46:10.440246: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4\n",
      "2025-11-13 16:46:10.440265: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-11-13 16:46:10.440271: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.92 GB\n",
      "2025-11-13 16:46:10.440282: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-11-13 16:46:10.440309: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-11-13 16:46:10.442169: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4\n",
      "2025-11-13 16:46:10.442189: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-11-13 16:46:10.442199: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.92 GB\n",
      "2025-11-13 16:46:10.442211: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-11-13 16:46:10.442219: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-11-13 16:46:10.443569: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4\n",
      "2025-11-13 16:46:10.443584: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-11-13 16:46:10.443592: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.92 GB\n",
      "2025-11-13 16:46:10.443603: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-11-13 16:46:10.443611: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-11-13 16:46:10.438827: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4\n",
      "2025-11-13 16:46:10.438854: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-11-13 16:46:10.438870: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.92 GB\n",
      "2025-11-13 16:46:10.438884: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-11-13 16:46:10.438894: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-11-13 16:46:10.440246: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4\n",
      "2025-11-13 16:46:10.440265: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-11-13 16:46:10.440271: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.92 GB\n",
      "2025-11-13 16:46:10.440282: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-11-13 16:46:10.440309: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-11-13 16:46:10.442169: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4\n",
      "2025-11-13 16:46:10.442189: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-11-13 16:46:10.442199: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.92 GB\n",
      "2025-11-13 16:46:10.442211: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-11-13 16:46:10.442219: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-11-13 16:46:10.443569: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4\n",
      "2025-11-13 16:46:10.443584: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-11-13 16:46:10.443592: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.92 GB\n",
      "2025-11-13 16:46:10.443603: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-11-13 16:46:10.443611: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-11-13 16:46:11.436347: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-11-13 16:46:11.441570: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-11-13 16:46:11.442007: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-11-13 16:46:11.442012: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-11-13 16:46:11.436347: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-11-13 16:46:11.441570: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-11-13 16:46:11.442007: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-11-13 16:46:11.442012: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "Grid search:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 24/64 [14:30<30:38, 45.97s/it]2025-11-13 17:03:00.072928: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4\n",
      "2025-11-13 17:03:00.072953: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-11-13 17:03:00.072969: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.92 GB\n",
      "2025-11-13 17:03:00.072982: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-11-13 17:03:00.072991: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-11-13 17:03:00.072928: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4\n",
      "2025-11-13 17:03:00.072953: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-11-13 17:03:00.072969: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.92 GB\n",
      "2025-11-13 17:03:00.072982: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-11-13 17:03:00.072991: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-11-13 17:03:00.948572: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-11-13 17:03:00.948572: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-11-13 17:03:32.692367: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4\n",
      "2025-11-13 17:03:32.692393: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-11-13 17:03:32.692421: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.92 GB\n",
      "2025-11-13 17:03:32.692455: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-11-13 17:03:32.692467: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-11-13 17:03:32.692367: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4\n",
      "2025-11-13 17:03:32.692393: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-11-13 17:03:32.692421: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.92 GB\n",
      "2025-11-13 17:03:32.692455: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-11-13 17:03:32.692467: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-11-13 17:03:33.649860: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-11-13 17:03:33.649860: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "Grid search:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/64 [17:55<28:36, 47.67s/it]2025-11-13 17:04:06.596754: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4\n",
      "2025-11-13 17:04:06.596776: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-11-13 17:04:06.596788: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.92 GB\n",
      "2025-11-13 17:04:06.596803: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-11-13 17:04:06.596813: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-11-13 17:04:06.596754: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4\n",
      "2025-11-13 17:04:06.596776: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-11-13 17:04:06.596788: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.92 GB\n",
      "2025-11-13 17:04:06.596803: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-11-13 17:04:06.596813: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-11-13 17:04:07.471700: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-11-13 17:04:07.471700: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-11-13 17:04:27.504037: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4\n",
      "2025-11-13 17:04:27.504062: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-11-13 17:04:27.504067: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.92 GB\n",
      "2025-11-13 17:04:27.504084: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-11-13 17:04:27.504094: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-11-13 17:04:27.504037: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4\n",
      "2025-11-13 17:04:27.504062: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-11-13 17:04:27.504067: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.92 GB\n",
      "2025-11-13 17:04:27.504084: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-11-13 17:04:27.504094: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-11-13 17:04:28.378027: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-11-13 17:04:28.378027: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "Grid search:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 36/64 [25:02<23:05, 49.48s/it]"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'conv_filters': [32, 64],           # ADVICE 13/11: Conv1D filters\n",
    "    'lstm_units': [64, 128],            # ADVICE 13/11: LSTM units\n",
    "    'dropout': [0.3, 0.4],              # Regularization\n",
    "    'learning_rate': [0.0005, 0.001],   # Optimizer\n",
    "    'label_smoothing': [0.05, 0.1],     # ADVICE 09/11: Label smoothing\n",
    "    'batch_size': [32, 64]              # Training batch size\n",
    "}\n",
    "\n",
    "# Generate all combinations\n",
    "param_names = list(param_grid.keys())\n",
    "param_values = list(param_grid.values())\n",
    "param_combinations = list(product(*param_values))\n",
    "\n",
    "print(\"ğŸ” Grid Search Configuration:\")\n",
    "print(f\"   Parameters to test: {param_names}\")\n",
    "print(f\"   Total combinations: {len(param_combinations)}\")\n",
    "print(f\"   Estimated time depends on n_jobs (parallel execution)\\n\")\n",
    "\n",
    "# Prepare one-hot targets once for label smoothing\n",
    "y_tr_grid = keras.utils.to_categorical(y_tr, n_classes)\n",
    "y_val_grid = keras.utils.to_categorical(y_val, n_classes)\n",
    "\n",
    "def build_model_for_grid(input_shape, num_classes, conv_filters, lstm_units, dropout):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv1D(conv_filters, 3, padding='same', activation='relu')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling1D(2)(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(conv_filters, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling1D(2)(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(lstm_units, return_sequences=False))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    return Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "def run_grid_experiment(param_tuple):\n",
    "    params = dict(zip(param_names, param_tuple))\n",
    "    conv_filters = params['conv_filters']\n",
    "    lstm_units = params['lstm_units']\n",
    "    dropout = params['dropout']\n",
    "    learning_rate = params['learning_rate']\n",
    "    label_smoothing = params['label_smoothing']\n",
    "    batch_size = params['batch_size']\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    model_grid = build_model_for_grid(\n",
    "        (WINDOW_SIZE, n_features),\n",
    "        n_classes,\n",
    "        conv_filters,\n",
    "        lstm_units,\n",
    "        dropout\n",
    ")\n",
    "\n",
    "    model_grid.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate, clipnorm=1.0),\n",
    "        loss=keras.losses.CategoricalCrossentropy(label_smoothing=label_smoothing),\n",
    "        metrics=[\n",
    "            keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "            MacroF1(num_classes=n_classes)\n",
    "        ]\n",
    ")\n",
    "\n",
    "    callbacks_local = [\n",
    "        EarlyStopping(monitor='val_macro_f1', patience=5, mode='max', restore_best_weights=True, verbose=0)\n",
    "]\n",
    "\n",
    "    history = model_grid.fit(\n",
    "        X_tr, y_tr_grid,\n",
    "        validation_data=(X_val, y_val_grid),\n",
    "        epochs=50,\n",
    "        batch_size=batch_size,\n",
    "        class_weight=class_weights_dict,\n",
    "        callbacks=callbacks_local,\n",
    "        verbose=0\n",
    ")\n",
    "\n",
    "    y_val_pred = model_grid.predict(X_val, verbose=0)\n",
    "    y_val_pred_classes = np.argmax(y_val_pred, axis=1)\n",
    "    f1_macro = f1_score(y_val, y_val_pred_classes, average='macro')\n",
    "\n",
    "    result = {\n",
    "        **params,\n",
    "        'f1_macro': f1_macro,\n",
    "        'epochs_trained': len(history.history['loss'])\n",
    "    }\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    return result\n",
    "\n",
    "max_jobs = min(4, max(1, (os.cpu_count() or 2) // 2))\n",
    "print(f\"âš™ï¸ Using {max_jobs} parallel workers (adjust max_jobs variable if needed)\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "grid_results = Parallel(n_jobs=max_jobs, backend='loky')(\n",
    "    delayed(run_grid_experiment)(params)\n",
    "    for params in tqdm(param_combinations, total=len(param_combinations), desc='Grid search')\n",
    ")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"âœ… Grid search completed in {elapsed_time/60:.1f} minutes\")\n",
    "\n",
    "results_df = pd.DataFrame(grid_results).sort_values('f1_macro', ascending=False)\n",
    "\n",
    "print('\\nğŸ† BEST CONFIGURATION:')\n",
    "best_config = results_df.iloc[0]\n",
    "print(f\"   F1 Macro Score: {best_config['f1_macro']:.4f}\\n\")\n",
    "print('   Parameters:')\n",
    "for param in param_names:\n",
    "    print(f\"     {param}: {best_config[param]}\")\n",
    "\n",
    "print('\\nğŸ“Š Grid Search Statistics:')\n",
    "print(f\"   Best F1 Macro: {results_df['f1_macro'].max():.4f}\")\n",
    "print(f\"   Worst F1 Macro: {results_df['f1_macro'].min():.4f}\")\n",
    "print(f\"   Mean F1 Macro: {results_df['f1_macro'].mean():.4f}\")\n",
    "print(f\"   Std F1 Macro: {results_df['f1_macro'].std():.4f}\")\n",
    "print(f\"   Improvement range: {results_df['f1_macro'].max() - results_df['f1_macro'].min():.4f}\")\n",
    "\n",
    "best_params = best_config[param_names].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grid_search_viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize grid search results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('ğŸ” Grid Search: Impact of Each Hyperparameter on F1 Macro Score', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, param in enumerate(param_names):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "\n",
    "    grouped = results_df.groupby(param)['f1_macro'].agg(['mean', 'std', 'count'])\n",
    "\n",
    "    x_pos = range(len(grouped))\n",
    "    ax.bar(x_pos, grouped['mean'], yerr=grouped['std'], alpha=0.7, capsize=5)\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(grouped.index)\n",
    "    ax.set_xlabel(param.replace('_', ' ').title(), fontweight='bold')\n",
    "    ax.set_ylabel('F1 Macro Score')\n",
    "    ax.set_title(f'Impact of {param.replace(\"_\", \" \").title()}')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "    best_idx = grouped['mean'].idxmax()\n",
    "    best_pos = list(grouped.index).index(best_idx)\n",
    "    ax.get_children()[best_pos].set_color('green')\n",
    "    ax.get_children()[best_pos].set_alpha(0.9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Top 10 configurations\n",
    "print('\\nğŸ“‹ Top 10 Configurations (sorted by F1 Macro):')\n",
    "print(results_df[param_names + ['f1_macro', 'epochs_trained']].head(10).to_string(index=False))\n",
    "\n",
    "print('\\nğŸ’¡ Insights:')\n",
    "print('   - Green bars show the best value for each hyperparameter')\n",
    "print('   - Error bars show std deviation across different combinations')\n",
    "print('   - Rankings use validation F1 macro only (accuracy not used)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "best_model_note",
   "metadata": {},
   "source": [
    "### Usare la Best Configuration\n",
    "\n",
    "Ora puoi:\n",
    "1. **Continuare con i parametri di default** delle sezioni seguenti, oppure\n",
    "2. **Modificare manualmente** le sezioni seguenti per usare `best_params`, oppure\n",
    "3. **Ritrainare** un nuovo modello qui sotto con la best configuration per piÃ¹ epoche"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compile_header",
   "metadata": {},
   "source": [
    "## 6. Compile con ADVICE 09/11 e 10/11\n",
    "\n",
    "**ADVICE 09/11**: Label smoothing  \n",
    "**ADVICE 10/11**: Gradient clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compile_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADVICE 10/11: Optimizer with gradient clipping\n",
    "# ADVICE 09/11: Loss with label smoothing\n",
    "optimizer = Adam(learning_rate=0.001, clipnorm=1.0)  # ADVICE 10/11\n",
    "loss = keras.losses.CategoricalCrossentropy(label_smoothing=0.1)  # ADVICE 09/11\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=[\n",
    "        keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "        MacroF1(num_classes=n_classes)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print('âœ… Model compiled with:')\n",
    "print('   - ADVICE 10/11: Gradient clipping (clipnorm=1.0)')\n",
    "print('   - ADVICE 09/11: Label smoothing (0.1)')\n",
    "print('   - Macro F1 metric to monitor validation performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepare_train",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to categorical for label smoothing\n",
    "y_tr_cat = keras.utils.to_categorical(y_tr, n_classes)\n",
    "y_val_cat = keras.utils.to_categorical(y_val, n_classes)\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_macro_f1', patience=10, mode='max', restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_macro_f1', factor=0.5, patience=5, verbose=1, mode='max'),\n",
    "    ModelCheckpoint('best_model_tf.h5', monitor='val_macro_f1', mode='max', save_best_only=True)\n",
    "]\n",
    "\n",
    "print('âœ… Training ready (monitoring val_macro_f1)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train_header",
   "metadata": {},
   "source": [
    "## 7. Training con Tutte le ADVICE Integrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ğŸš€ Training with ALL ADVICE integrated:\\n')\n",
    "print('âœ… 11/11 - Autocorrelation window')\n",
    "print('âœ… 12/11 - Time features (cyclical)')\n",
    "print('âœ… 13/11 - Conv1D + LSTM')\n",
    "print('âœ… 10/11 - Gradient clipping')\n",
    "print('âœ… 09/11 - Label smoothing')\n",
    "print('âœ… 08/11 - Class weighting')\n",
    "print('âœ… 07/11 - Categorical mapped')\n",
    "print('âœ… Monitoring val_macro_f1 for best model selection\\n')\n",
    "\n",
    "history = model.fit(\n",
    "    X_tr, y_tr_cat,\n",
    "    validation_data=(X_val, y_val_cat),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    class_weight=class_weights_dict,  # ADVICE 08/11\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print('\\nğŸ‰ Training complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "ax1.plot(history.history['loss'], label='Train')\n",
    "ax1.plot(history.history['val_loss'], label='Val')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training History')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(history.history['accuracy'], label='Train')\n",
    "ax2.plot(history.history['val_accuracy'], label='Val')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval_header",
   "metadata": {},
   "source": [
    "## 8. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eval_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "y_pred_prob = model.predict(X_val)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "print('ğŸ“Š Classification Report:\\n')\n",
    "print(classification_report(y_val, y_pred, target_names=label_encoder.classes_, digits=4))\n",
    "\n",
    "# F1 Score\n",
    "f1_macro = f1_score(y_val, y_pred, average='macro')\n",
    "print(f'\\nğŸ¯ F1 Score (macro): {f1_macro:.4f}')\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=label_encoder.classes_,\n",
    "            yticklabels=label_encoder.classes_, ax=ax)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## ğŸ“ Summary\n",
    "\n",
    "Pipeline completa e funzionante con tutte le ADVICE integrate:\n",
    "\n",
    "1. **ADVICE 11/11**: Window size da autocorrelazione\n",
    "2. **ADVICE 12/11**: Time features ciclici\n",
    "3. **ADVICE 13/11**: Conv1D + LSTM\n",
    "4. **ADVICE 10/11**: Gradient clipping (clipnorm=1.0)\n",
    "5. **ADVICE 09/11**: Label smoothing (0.1)\n",
    "6. **ADVICE 08/11**: Class weighting (balanced)\n",
    "7. **ADVICE 07/11**: Categorical mapping\n",
    "\n",
    "**Dataset**: 661 samples Ã— 160 timesteps Ã— 38 features  \n",
    "**Classes**: no_pain, low_pain, high_pain (sbilanciato)\n",
    "\n",
    "âœ… **Pronto per essere eseguito end-to-end!** ğŸ´â€â˜ ï¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test_header",
   "metadata": {},
   "source": [
    "## 9. Test Set Prediction e Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "X_test = pd.read_csv('pirate_pain_test.csv')\n",
    "\n",
    "print(f'ğŸ“Š Test Data:')\n",
    "print(f'   Shape: {X_test.shape}')\n",
    "print(f'   Samples: {X_test[\"sample_index\"].nunique()}')\n",
    "print(f'   Timesteps/sample: {X_test.groupby(\"sample_index\").size().iloc[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preproc_test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply same preprocessing to test\n",
    "X_test_proc = X_test.copy()\n",
    "\n",
    "# ADVICE 07/11: Map categorical\n",
    "for col, mapping in cat_map.items():\n",
    "    X_test_proc[col] = X_test_proc[col].map(mapping).fillna(0).astype(int)\n",
    "\n",
    "# ADVICE 12/11: Add time features\n",
    "max_time_test = X_test_proc['time'].max()\n",
    "X_test_proc['time_sin'] = np.sin(2*np.pi*X_test_proc['time']/max_time_test)\n",
    "X_test_proc['time_cos'] = np.cos(2*np.pi*X_test_proc['time']/max_time_test)\n",
    "X_test_proc['time_norm'] = X_test_proc['time']/max_time_test\n",
    "\n",
    "print('âœ… Test preprocessing done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_predict",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create windows for test and predict\n",
    "print('ğŸ”„ Creating test windows and predicting...')\n",
    "\n",
    "test_sample_indices = X_test['sample_index'].unique()\n",
    "sample_predictions = {}  # Store predictions per sample\n",
    "\n",
    "for sid in tqdm(test_sample_indices, desc='Predicting'):\n",
    "    # Create windows for this sample\n",
    "    windows = create_windows(X_test_proc, sid, WINDOW_SIZE, WINDOW_STRIDE)\n",
    "    \n",
    "    if len(windows) > 0:\n",
    "        # Convert to array and normalize\n",
    "        X_sample = np.array(windows, dtype=np.float32)\n",
    "        X_sample = scaler.transform(\n",
    "            X_sample.reshape(-1, X_sample.shape[-1])\n",
    "        ).reshape(X_sample.shape)\n",
    "        \n",
    "        # Predict probabilities for all windows\n",
    "        probs = model.predict(X_sample, verbose=0)\n",
    "        \n",
    "        # Aggregate: average probabilities across windows, then argmax\n",
    "        avg_probs = probs.mean(axis=0)\n",
    "        pred_class = np.argmax(avg_probs)\n",
    "        \n",
    "        sample_predictions[sid] = pred_class\n",
    "\n",
    "print(f'âœ… Predicted {len(sample_predictions)} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_submission",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission DataFrame\n",
    "submission_data = []\n",
    "for sid in sorted(sample_predictions.keys()):\n",
    "    pred_class = sample_predictions[sid]\n",
    "    pred_label = label_encoder.classes_[pred_class]\n",
    "    submission_data.append({\n",
    "        'sample_index': sid,\n",
    "        'label': pred_label\n",
    "    })\n",
    "\n",
    "submission = pd.DataFrame(submission_data)\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print('âœ… Submission created!')\n",
    "print(f'   Shape: {submission.shape}')\n",
    "print(f'   Columns: {list(submission.columns)}')\n",
    "print(f'\\nğŸ“Š Predicted label distribution:')\n",
    "print(submission['label'].value_counts())\n",
    "print(f'\\nğŸ’¾ Saved to: submission.csv')\n",
    "display(submission.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1_analysis_header",
   "metadata": {},
   "source": [
    "## 10. F1 Score Analysis e Ottimizzazione\n",
    "\n",
    "Analizziamo come massimizzare l'F1 macro score sulla validation per migliorare le performance sul test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze F1 score per class\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "print('ğŸ¯ F1 Score Analysis on Validation Set\\n')\n",
    "\n",
    "# Get predictions\n",
    "y_pred_prob = model.predict(X_val)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Calculate per-class metrics\n",
    "f1_per_class = f1_score(y_val, y_pred, average=None)\n",
    "precision_per_class = precision_score(y_val, y_pred, average=None)\n",
    "recall_per_class = recall_score(y_val, y_pred, average=None)\n",
    "\n",
    "print('ğŸ“Š Per-Class Metrics:\\n')\n",
    "for i, label_name in enumerate(label_encoder.classes_):\n",
    "    print(f'{label_name}:')\n",
    "    print(f'  Precision: {precision_per_class[i]:.4f}')\n",
    "    print(f'  Recall:    {recall_per_class[i]:.4f}')\n",
    "    print(f'  F1 Score:  {f1_per_class[i]:.4f}')\n",
    "    print()\n",
    "\n",
    "# Overall F1 scores\n",
    "f1_macro = f1_score(y_val, y_pred, average='macro')\n",
    "f1_weighted = f1_score(y_val, y_pred, average='weighted')\n",
    "\n",
    "print(f'ğŸ¯ Overall F1 Scores:')\n",
    "print(f'   F1 Macro (challenge metric):    {f1_macro:.4f}')\n",
    "print(f'   F1 Weighted:                     {f1_weighted:.4f}')\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Per-class F1 scores\n",
    "ax1 = axes[0]\n",
    "x_pos = np.arange(len(label_encoder.classes_))\n",
    "ax1.bar(x_pos, f1_per_class, color=['green', 'orange', 'red'])\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels(label_encoder.classes_, rotation=45)\n",
    "ax1.set_ylabel('F1 Score')\n",
    "ax1.set_title('F1 Score per Class (Validation)')\n",
    "ax1.axhline(y=f1_macro, color='blue', linestyle='--', label=f'Macro Avg: {f1_macro:.4f}')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Precision-Recall per class\n",
    "ax2 = axes[1]\n",
    "x_pos = np.arange(len(label_encoder.classes_))\n",
    "width = 0.35\n",
    "ax2.bar(x_pos - width/2, precision_per_class, width, label='Precision')\n",
    "ax2.bar(x_pos + width/2, recall_per_class, width, label='Recall')\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(label_encoder.classes_, rotation=45)\n",
    "ax2.set_ylabel('Score')\n",
    "ax2.set_title('Precision vs Recall per Class')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1_tips",
   "metadata": {},
   "source": [
    "## ğŸ’¡ Tips per Massimizzare F1 Macro Score\n",
    "\n",
    "### 1. Class Weighting (giÃ  applicato âœ…)\n",
    "Il class weighting aiuta con lo sbilanciamento, ma potrebbe non essere sufficiente.\n",
    "\n",
    "### 2. Threshold Tuning\n",
    "Invece di usare argmax, prova threshold diversi per ogni classe:\n",
    "```python\n",
    "# Esempio: bias verso classi minoritarie\n",
    "thresholds = [0.3, 0.4, 0.5]  # per no_pain, low_pain, high_pain\n",
    "```\n",
    "\n",
    "### 3. Ensemble di Predizioni\n",
    "Invece di media semplice sulle finestre, prova:\n",
    "- Media pesata (finestre centrali contano di piÃ¹)\n",
    "- Voting (maggioranza tra finestre)\n",
    "- Max pooling delle probabilitÃ \n",
    "\n",
    "### 4. Data Augmentation\n",
    "Per le classi minoritarie:\n",
    "- Noise injection\n",
    "- Time warping\n",
    "- Window shift augmentation\n",
    "\n",
    "### 5. Focal Loss\n",
    "Invece di label smoothing, usa focal loss per dare piÃ¹ peso agli esempi difficili:\n",
    "```python\n",
    "# Focal loss = CE * (1-p)^gamma\n",
    "# Mette piÃ¹ enfasi su campioni classificati male\n",
    "```\n",
    "\n",
    "### 6. Class-specific Hyperparameters\n",
    "Allena modelli separati o usa attention mechanism per dare piÃ¹ capacitÃ  alle classi minoritarie.\n",
    "\n",
    "### 7. Cross-Validation\n",
    "Usa K-fold CV per avere stime piÃ¹ robuste dell'F1:\n",
    "```python\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# 5-fold CV per vedere stabilitÃ  F1\n",
    "```\n",
    "\n",
    "### ğŸ¯ Focus sulle Classi Minoritarie\n",
    "F1 macro = media delle F1 per classe, quindi:\n",
    "- **low_pain** e **high_pain** hanno peso uguale a **no_pain**\n",
    "- Migliora recall su classi minoritarie\n",
    "- Monitora confusion matrix per vedere dove sbaglia\n",
    "\n",
    "### âš ï¸ Overfitting Warning\n",
    "Se F1 validation >> F1 test:\n",
    "- Aumenta regolarizzazione (dropout, weight decay)\n",
    "- Riduci model complexity\n",
    "- Usa early stopping piÃ¹ aggressivo\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
